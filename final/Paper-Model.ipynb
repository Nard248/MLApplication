{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:30:11.253475Z",
     "start_time": "2025-03-12T13:30:04.456640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "from models import *\n",
    "\n",
    "# Load data\n",
    "state = np.load(\"data/Data-dmd-11-03/states_processed_cropped.npy\")\n",
    "myu_full = np.load(\"data/Data-dmd-11-03/myus_binarized_processed_cropped.npy\")\n",
    "myu_original = np.load(\"data/Data-dmd-11-03/myu_cropped.npy\")\n",
    "\n",
    "print(\"State shape:\", state.shape, state.dtype)  # (350,530,880), complex128\n",
    "print(\"Myu shape:  \", myu_full.shape, myu_full.dtype)  # (350,530,880), uint16\n",
    "print(\"Myu shape:  \", myu_original.shape, myu_original.dtype)  # (350,530,880), uint16"
   ],
   "id": "34f5b7a1e98d8c75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape: (1500, 360, 637) complex64\n",
      "Myu shape:   (1500, 360, 637) uint8\n",
      "Myu shape:   (1500, 742, 1356) uint8\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:30:11.659592Z",
     "start_time": "2025-03-12T13:30:11.262515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract real and imaginary parts\n",
    "A_r_data = state.real\n",
    "A_i_data = state.imag\n",
    "\n",
    "# Configuration\n",
    "Nt, Nx, Ny = state.shape\n",
    "dt, dx, dy = 0.05, 0.3, 0.3\n",
    "Nx_down, Ny_down = 22, 26\n",
    "degrade_x = Nx // Nx_down\n",
    "degrade_y = Ny // Ny_down\n",
    "\n",
    "# Sample data points\n",
    "n_data = 20000\n",
    "idx_t = np.random.randint(0, Nt, size=n_data)\n",
    "idx_x = np.random.randint(0, Nx, size=n_data)\n",
    "idx_y = np.random.randint(0, Ny, size=n_data)\n",
    "\n",
    "t_vals = np.arange(Nt) * dt\n",
    "x_vals = np.arange(Nx) * dx\n",
    "y_vals = np.arange(Ny) * dy\n",
    "\n",
    "t_data_np = t_vals[idx_t]\n",
    "x_data_np = x_vals[idx_x]\n",
    "y_data_np = y_vals[idx_y]\n",
    "\n",
    "Ar_data_np = A_r_data[idx_t, idx_x, idx_y]\n",
    "Ai_data_np = A_i_data[idx_t, idx_x, idx_y]\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert to tensors\n",
    "x_data_t = torch.tensor(x_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "y_data_t = torch.tensor(y_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "t_data_t = torch.tensor(t_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "Ar_data_t = torch.tensor(Ar_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "Ai_data_t = torch.tensor(Ai_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "\n",
    "# Collocation points for PDE constraints\n",
    "n_coll = 20000\n",
    "t_eqs_np = np.random.uniform(0, t_vals[-1], size=n_coll)\n",
    "x_eqs_np = np.random.uniform(0, x_vals[-1], size=n_coll)\n",
    "y_eqs_np = np.random.uniform(0, y_vals[-1], size=n_coll)\n",
    "\n",
    "x_eqs_t = torch.tensor(x_eqs_np, dtype=torch.float32, device=device, requires_grad=True).view(-1, 1)\n",
    "y_eqs_t = torch.tensor(y_eqs_np, dtype=torch.float32, device=device, requires_grad=True).view(-1, 1)\n",
    "t_eqs_t = torch.tensor(t_eqs_np, dtype=torch.float32, device=device, requires_grad=True).view(-1, 1)"
   ],
   "id": "4e33863d86ae2963",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:30:12.291740Z",
     "start_time": "2025-03-12T13:30:12.252539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"TimeBlockerV2_WithValidation\"\n",
    "output_dir = \"./results\"\n",
    "\n",
    "model = NPINN_PRO_MAX_TIMEBLOCK_V2(\n",
    "    layers=[3, 128, 256, 256, 128, 2],  # Deeper and wider architecture\n",
    "    Nt=Nt, Nx=Nx, Ny=Ny,\n",
    "    Nx_down=Nx_down, Ny_down=Ny_down,\n",
    "    dt=dt, dx=dx, dy=dy,\n",
    "    degrade_x=degrade_x, degrade_y=degrade_y,\n",
    "    delta=0.01,\n",
    "    weight_pde=0.1,\n",
    "    device=device,\n",
    "    degrade_t=150,\n",
    ").to(device)"
   ],
   "id": "78d3a8c4bfacb2d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:31:28.812341Z",
     "start_time": "2025-03-12T13:30:12.332261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.train_model(\n",
    "    x_data=x_data_t,\n",
    "    y_data=y_data_t,\n",
    "    t_data=t_data_t,\n",
    "    A_r_data=Ar_data_t,\n",
    "    A_i_data=Ai_data_t,\n",
    "    x_eqs=x_eqs_t,\n",
    "    y_eqs=y_eqs_t,\n",
    "    t_eqs=t_eqs_t,\n",
    "    n_epochs=120,\n",
    "    lr=1e-3,\n",
    "    batch_size=2048,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    video_freq=120,\n",
    "    state_exp=state,\n",
    "    myu_full_exp=myu_full,\n",
    "    x_vals=x_vals,\n",
    "    y_vals=y_vals,\n",
    "    t_vals=t_vals,\n",
    "    device=device,\n",
    "    validation_split=0.2,  # Use 20% of data for validation\n",
    "    val_freq=50            # Validate every 50 epochs\n",
    ")\n",
    "\n",
    "# After training, we can analyze the results\n",
    "model_folder = os.path.join(output_dir, model_name)\n",
    "losses_df = pd.read_csv(os.path.join(model_folder, f\"{model_name}_losses.csv\"))\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Final training loss: {losses_df['train_total_loss'].iloc[-1]:.6e}\")\n",
    "print(f\"Final validation loss: {losses_df['val_total_loss'].iloc[-1]:.6e}\")\n",
    "\n",
    "# Load best model\n",
    "best_model_path = os.path.join(model_folder, f\"{model_name}_best.pt\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "print(f\"Best model loaded from {best_model_path}\")\n",
    "\n",
    "# Optional: Generate final validation visualization\n",
    "print(\"Generating final visualization...\")\n",
    "final_vid_path = os.path.join(model_folder, \"videos\", f\"{model_name}_final_visualization\")\n",
    "generate_video(state, myu_full, model, x_vals, y_vals, t_vals, device=device, output_path=final_vid_path)\n",
    "print(f\"Final visualization saved to {final_vid_path}\")"
   ],
   "id": "4a68053d4dc1182b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with 16000 training samples and 4000 validation samples\n",
      "Epoch 0: New best model saved (val_loss=1.2974e+00)\n",
      "Epoch 0: Train [total=2.8273e+00, data=1.9626e+00, PDE=8.6461e+00] | Val [total=1.2974e+00, data=1.2191e+00, PDE=7.8298e-01]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mA_r_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAr_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mA_i_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAi_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_eqs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_eqs_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_eqs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_eqs_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_eqs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_eqs_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m120\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2048\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvideo_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m120\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_exp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmyu_full_exp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmyu_full\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_vals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_vals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_vals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_vals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_vals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_vals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Use 20% of data for validation\u001B[39;49;00m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# Validate every 50 epochs\u001B[39;49;00m\n\u001B[0;32m     24\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# After training, we can analyze the results\u001B[39;00m\n\u001B[0;32m     27\u001B[0m model_folder \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_dir, model_name)\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\final\\models.py:1521\u001B[0m, in \u001B[0;36mNPINN_PRO_MAX_TIMEBLOCK_V2.train_model\u001B[1;34m(self, x_data, y_data, t_data, A_r_data, A_i_data, x_eqs, y_eqs, t_eqs, n_epochs, lr, batch_size, model_name, output_dir, video_freq, state_exp, myu_full_exp, x_vals, y_vals, t_vals, device, validation_split, val_freq)\u001B[0m\n\u001B[0;32m   1518\u001B[0m pde_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_pde(x_e, y_e, t_e)\n\u001B[0;32m   1520\u001B[0m \u001B[38;5;66;03m# Gradient penalty\u001B[39;00m\n\u001B[1;32m-> 1521\u001B[0m grad_penalty \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient_penalty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_e\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_e\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_e\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# Total loss\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m loss \u001B[38;5;241m=\u001B[39m data_loss \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_pde \u001B[38;5;241m*\u001B[39m pde_loss \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.01\u001B[39m \u001B[38;5;241m*\u001B[39m grad_penalty\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\final\\models.py:1381\u001B[0m, in \u001B[0;36mNPINN_PRO_MAX_TIMEBLOCK_V2.gradient_penalty\u001B[1;34m(self, x, y, t)\u001B[0m\n\u001B[0;32m   1378\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Additional regularization for derivatives\"\"\"\u001B[39;00m\n\u001B[0;32m   1379\u001B[0m A_r, A_i \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet_A(x, y, t)\n\u001B[1;32m-> 1381\u001B[0m gradients_r \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1382\u001B[0m \u001B[43m    \u001B[49m\u001B[43mA_r\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1383\u001B[0m gradients_i \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mgrad(\n\u001B[0;32m   1384\u001B[0m     A_i\u001B[38;5;241m.\u001B[39msum(), x, create_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, retain_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1386\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (gradients_r\u001B[38;5;241m.\u001B[39mpow(\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;241m+\u001B[39m gradients_i\u001B[38;5;241m.\u001B[39mpow(\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39msum()) \u001B[38;5;241m/\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:496\u001B[0m, in \u001B[0;36mgrad\u001B[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001B[0m\n\u001B[0;32m    492\u001B[0m     result \u001B[38;5;241m=\u001B[39m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(\n\u001B[0;32m    493\u001B[0m         grad_outputs_\n\u001B[0;32m    494\u001B[0m     )\n\u001B[0;32m    495\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 496\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_outputs_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m materialize_grads:\n\u001B[0;32m    506\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[0;32m    507\u001B[0m         result[i] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tensor_like(inputs[i])\n\u001B[0;32m    508\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(inputs))\n\u001B[0;32m    509\u001B[0m     ):\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "91d822e4bd35aedd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
