{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T11:43:20.906886Z",
     "start_time": "2025-03-12T11:43:05.477622Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.load(r\"C:\\Users\\Alex\\Desktop\\data-processing\\cropped_and_ready\\states_processed_cropped.npy\")[:120]\n",
    "myu = np.load(r\"C:\\Users\\Alex\\Desktop\\data-processing\\cropped_and_ready\\myus_binarized_processed_cropped.npy\")[:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "myu_original = np.load(r\"O:\\Data-New\\Data-dmd-11-03\\myu_cropped.npy\")[:120, 0::2, 0::2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape: (120, 360, 637) complex64\n",
      "Myu shape:   (120, 360, 637) uint8\n",
      "Myu original shape:   (120, 371, 678) uint8\n"
     ]
    }
   ],
   "source": [
    "print(\"State shape:\",           state.shape,        state.dtype)\n",
    "print(\"Myu shape:  \",           myu.shape,          myu.dtype)\n",
    "print(\"Myu original shape:  \",  myu_original.shape, myu_original.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_r_data = state.real\n",
    "A_i_data = state.imag\n",
    "\n",
    "Nt, Nx, Ny = state.shape\n",
    "dt, dx, dy = 0.05, 0.3, 0.3  # Example values\n",
    "Nx_down, Ny_down = 18, 20\n",
    "degrade_x = Nx // Nx_down  # 530//10=53\n",
    "degrade_y = Ny // Ny_down  # 880//10=88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = 20000\n",
    "idx_t = np.random.randint(0, Nt, size=n_data)\n",
    "idx_x = np.random.randint(0, Nx, size=n_data)\n",
    "idx_y = np.random.randint(0, Ny, size=n_data)\n",
    "\n",
    "t_vals = np.arange(Nt) * dt\n",
    "x_vals = np.arange(Nx) * dx\n",
    "y_vals = np.arange(Ny) * dy\n",
    "\n",
    "t_data_np = t_vals[idx_t]\n",
    "x_data_np = x_vals[idx_x]\n",
    "y_data_np = y_vals[idx_y]\n",
    "\n",
    "Ar_data_np = A_r_data[idx_t, idx_x, idx_y]\n",
    "Ai_data_np = A_i_data[idx_t, idx_x, idx_y]\n",
    "\n",
    "x_data_t = torch.tensor(x_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "y_data_t = torch.tensor(y_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "t_data_t = torch.tensor(t_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "Ar_data_t = torch.tensor(Ar_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "Ai_data_t = torch.tensor(Ai_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "\n",
    "n_coll = 20000\n",
    "t_eqs_np = np.random.uniform(0, t_vals[-1], size=n_coll)\n",
    "x_eqs_np = np.random.uniform(0, x_vals[-1], size=n_coll)\n",
    "y_eqs_np = np.random.uniform(0, y_vals[-1], size=n_coll)\n",
    "\n",
    "x_eqs_t = torch.tensor(x_eqs_np, dtype=torch.float32, device=device, requires_grad=True).view(-1, 1)\n",
    "y_eqs_t = torch.tensor(y_eqs_np, dtype=torch.float32, device=device, requires_grad=True).view(-1, 1)\n",
    "t_eqs_t = torch.tensor(t_eqs_np, dtype=torch.float32, device=device, requires_grad=True).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NPINN_PRO_MAX_TIMEBLOCK_V2(\n",
       "  (dnn): ImprovedDNN(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ResBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "      (5): ResBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "      (6): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): GELU(approximate='none')\n",
       "      (9): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): GELU(approximate='none')\n",
       "      (12): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): GELU(approximate='none')\n",
       "      (15): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = NPINN_PRO_MAX_TIMEBLOCK_V2(\n",
    "    layers=[3, 128, 256, 256, 128, 2],\n",
    "    Nt=Nt, Nx=Nx, Ny=Ny,\n",
    "    Nx_down=Nx_down, Ny_down=Ny_down,\n",
    "    dt=dt, dx=dx, dy=dy,\n",
    "    degrade_x=degrade_x, degrade_y=degrade_y,\n",
    "    delta=0.01,\n",
    "    weight_pde=0.1,\n",
    "    device=device,\n",
    "    degrade_t=10\n",
    ").to(device)\n",
    "\n",
    "model_path = r\"C:\\Users\\Alex\\Desktop\\gl-pinn-new\\TimeBlockerV2_Test_2_final_2000.pt\"\n",
    "\n",
    "model_state = torch.load(model_path, map_location=device, weights_only=True)\n",
    "model_5.load_state_dict(model_state)\n",
    "model_5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'./videos_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_frame(pinn_prod, original_prod, abs_diff, mu_pred, mu_full, mu_original):\n",
    "    vmin = np.min(original_prod)\n",
    "    vmax = np.max(original_prod)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    spec = gridspec.GridSpec(ncols=2, nrows=3, figure=fig)\n",
    "\n",
    "    ax1 = fig.add_subplot(spec[0, 0])\n",
    "    ax2 = fig.add_subplot(spec[0, 1])\n",
    "    ax3 = fig.add_subplot(spec[1, 0])\n",
    "    ax4 = fig.add_subplot(spec[1, 1])\n",
    "    ax5 = fig.add_subplot(spec[2, 0])\n",
    "    ax6 = fig.add_subplot(spec[2, 1])\n",
    "\n",
    "    im1 = ax1.imshow(original_prod, cmap=\"viridis\", origin=\"lower\", vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title(\"Original: Real x Imag\")\n",
    "    ax1.set_xlabel(\"X\")\n",
    "    ax1.set_ylabel(\"Y\")\n",
    "\n",
    "    im2 = ax2.imshow(pinn_prod, cmap=\"viridis\", origin=\"lower\", vmin=vmin, vmax=vmax)\n",
    "    ax2.set_title(\"PINN: Real x Imag\")\n",
    "    ax2.set_xlabel(\"X\")\n",
    "    ax2.set_ylabel(\"Y\")\n",
    "\n",
    "    im3 = ax3.imshow(abs_diff, cmap=\"viridis\", origin=\"lower\")\n",
    "    ax3.set_title(\"Absolute Difference\")\n",
    "    ax3.set_xlabel(\"X\")\n",
    "    ax3.set_ylabel(\"Y\")\n",
    "\n",
    "    im4 = ax4.imshow(mu_full, cmap=\"viridis\", origin=\"lower\")\n",
    "    ax4.set_title(\"Original μ (Old)\")\n",
    "    ax4.set_xlabel(\"X\")\n",
    "    ax4.set_ylabel(\"Y\")\n",
    "\n",
    "    im5 = ax5.imshow(mu_original, cmap=\"viridis\", origin=\"lower\")\n",
    "    ax5.set_title(\"Original μ (New)\")\n",
    "    ax5.set_xlabel(\"X\")\n",
    "    ax5.set_ylabel(\"Y\")\n",
    "\n",
    "    im6 = ax6.imshow(mu_pred, cmap=\"viridis\", origin=\"lower\")\n",
    "    ax6.set_title(\"Predicted μ\")\n",
    "    ax6.set_xlabel(\"X\")\n",
    "    ax6.set_ylabel(\"Y\")\n",
    "\n",
    "    fig.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n",
    "    fig.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)\n",
    "    fig.colorbar(im3, ax=ax3, fraction=0.046, pad=0.04)\n",
    "    fig.colorbar(im4, ax=ax4, fraction=0.046, pad=0.04)\n",
    "    fig.colorbar(im5, ax=ax5, fraction=0.046, pad=0.04)\n",
    "    fig.colorbar(im6, ax=ax6, fraction=0.046, pad=0.04)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    image = np.frombuffer(fig.canvas.buffer_rgba(), dtype='uint8').reshape(height, width, 4)\n",
    "    plt.close(fig)\n",
    "    return image[:, :, :3]\n",
    "\n",
    "\n",
    "def create_video(output_path, pinn_prod_frames, original_prod_frames, abs_diff_frames, mu_pred_frames, mu_full_frames, mu_original_frames, fps=30, additional_title=\"\"):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    video_path = os.path.join(output_path, f\"output_video_{datetime.now().strftime('%Y%m%d%H%M%S')}_{additional_title}.mp4\")\n",
    "\n",
    "    first_frame = create_combined_frame(\n",
    "        pinn_prod_frames[0], original_prod_frames[0], abs_diff_frames[0], mu_pred_frames[0], mu_full_frames[0], mu_original_frames[0]\n",
    "    )\n",
    "    height, width, _ = first_frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(len(pinn_prod_frames)), desc=\"Creating video\"):\n",
    "            combined_frame = create_combined_frame(\n",
    "                pinn_prod_frames[i], original_prod_frames[i], abs_diff_frames[i], mu_pred_frames[i], mu_full_frames[i], mu_original_frames[i]\n",
    "            )\n",
    "            video_writer.write(cv2.cvtColor(combined_frame, cv2.COLOR_RGB2BGR))\n",
    "        video_writer.release()\n",
    "    except Exception as e:\n",
    "        video_writer.release()\n",
    "        raise RuntimeError(f\"Failed to create video: {e}\")\n",
    "\n",
    "    print(f\"Video saved at: {video_path}\")\n",
    "\n",
    "\n",
    "def generate_video(state, mu_full, mu_full_original, model, x_vals, y_vals, t_vals, device, output_path):\n",
    "\n",
    "    pinn_prod_frames, original_state_prod_frames, abs_diff_frames, mu_pred_frames, mu_full_frames, mu_original_frames = [], [], [], [], [], []\n",
    "    mu_expanded = model.expand_myu_full(do_binarize=True, scale_255=True)\n",
    "    \n",
    "    for i, t_val in enumerate(tqdm(t_vals, desc=\"Generating frames\")):\n",
    "        X, Y = np.meshgrid(x_vals, y_vals)\n",
    "        XX = X.ravel()\n",
    "        YY = Y.ravel()\n",
    "        TT = np.full_like(XX, t_val)\n",
    "\n",
    "        x_test_t = torch.tensor(XX, dtype=torch.float32, device=device).view(-1, 1)\n",
    "        y_test_t = torch.tensor(YY, dtype=torch.float32, device=device).view(-1, 1)\n",
    "        t_test_t = torch.tensor(TT, dtype=torch.float32, device=device).view(-1, 1)\n",
    "\n",
    "        A_r_pred, A_i_pred = model.predict(x_test_t, y_test_t, t_test_t)\n",
    "        A_r_pred_2d = A_r_pred.reshape(X.shape)\n",
    "        A_i_pred_2d = A_i_pred.reshape(X.shape)\n",
    "\n",
    "        pinn_prod = A_r_pred_2d * A_i_pred_2d\n",
    "        original_prod = state[i].real * state[i].imag\n",
    "        \n",
    "        if pinn_prod.shape != original_prod.shape:\n",
    "            pinn_prod = pinn_prod.T\n",
    "    \n",
    "        abs_diff = np.abs(original_prod - pinn_prod)\n",
    "\n",
    "        mu_pred_2d = mu_expanded[i]\n",
    "        mu_full_2d = mu_full[i]\n",
    "        mu_original_2d = mu_full_original[i]\n",
    "\n",
    "        pinn_prod_frames.append(pinn_prod)\n",
    "        original_state_prod_frames.append(original_prod)\n",
    "        abs_diff_frames.append(abs_diff)\n",
    "        mu_pred_frames.append(mu_pred_2d)\n",
    "        mu_full_frames.append(mu_full_2d)\n",
    "        mu_original_frames.append(mu_original_2d)\n",
    "\n",
    "    pinn_prod_frames           = np.array(pinn_prod_frames)\n",
    "    original_state_prod_frames = np.array(original_state_prod_frames)\n",
    "    abs_diff_frames            = np.array(abs_diff_frames)\n",
    "    mu_pred_frames             = np.array(mu_pred_frames)\n",
    "    mu_full_frames             = np.array(mu_full_frames)\n",
    "    mu_original_frames         = np.array(mu_full_original)\n",
    "\n",
    "    create_video(output_path, pinn_prod_frames, original_state_prod_frames, abs_diff_frames, mu_pred_frames, mu_full_frames, mu_original_frames, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating frames: 100%|██████████| 120/120 [00:08<00:00, 14.22it/s]\n",
      "Creating video: 100%|██████████| 120/120 [01:00<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at: ./videos_test\\output_video_20250312123201_.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_video(\n",
    "    state=state,\n",
    "    mu_full=myu,\n",
    "    model=model_5, \n",
    "    x_vals=x_vals, \n",
    "    y_vals=y_vals,\n",
    "    t_vals=t_vals,\n",
    "    mu_full_original=myu_original, \n",
    "    device=device, \n",
    "    output_path=video_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
