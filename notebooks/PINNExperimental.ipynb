{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-23T20:06:39.209298Z",
     "start_time": "2025-01-23T20:06:36.475143Z"
    }
   },
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def prepare_ndarray_frame(data, vmin, vmax, cmap='viridis', title=\"\"):\n",
    "    \"\"\"Prepares a frame from a numpy array for video by plotting it and returning the image as an ndarray.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    im = ax.imshow(data, cmap=cmap, origin='lower', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.axis('off')\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    image = np.frombuffer(fig.canvas.buffer_rgba(), dtype='uint8').reshape(height, width, 4)\n",
    "    plt.close(fig)\n",
    "    return image[:, :, :3]\n",
    "\n",
    "def create_combined_frame(pinn_prod, sim_prod, mu_pred, mu_full, vmin_pinn, vmax_pinn, vmin_mu, vmax_mu):\n",
    "    \"\"\"Creates a combined frame showing predicted and original states and mu-fields.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "    axes[0].imshow(pinn_prod, cmap=\"viridis\", origin=\"lower\", vmin=vmin_pinn, vmax=vmax_pinn)\n",
    "    axes[0].set_title(\"PINN: Real × Imag\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(sim_prod, cmap=\"viridis\", origin=\"lower\", vmin=vmin_pinn, vmax=vmax_pinn)\n",
    "    axes[1].set_title(\"Sim: Real × Imag\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(mu_pred, cmap=\"viridis\", origin=\"lower\", vmin=vmin_mu, vmax=vmax_mu)\n",
    "    axes[2].set_title(\"Predicted μ\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    axes[3].imshow(mu_full, cmap=\"viridis\", origin=\"lower\", vmin=vmin_mu, vmax=vmax_mu)\n",
    "    axes[3].set_title(\"Original μ\")\n",
    "    axes[3].axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    image = np.frombuffer(fig.canvas.buffer_rgba(), dtype='uint8').reshape(height, width, 4)\n",
    "    plt.close(fig)\n",
    "    return image[:, :, :3]  # Return only RGB\n",
    "\n",
    "\n",
    "def create_video(output_path, pinn_prod_frames, sim_prod_frames, mu_pred_frames, mu_full_frames, fps=30):\n",
    "    \"\"\"Creates a video combining frames.\"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    video_path = os.path.join(output_path, f\"output_video_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.mp4\")\n",
    "    vmin_pinn, vmax_pinn = np.min(pinn_prod_frames), np.max(pinn_prod_frames)\n",
    "    vmin_mu, vmax_mu = np.min(mu_pred_frames), np.max(mu_pred_frames)\n",
    "\n",
    "    first_frame = create_combined_frame(\n",
    "        pinn_prod_frames[0], sim_prod_frames[0], mu_pred_frames[0], mu_full_frames[0],\n",
    "        vmin_pinn, vmax_pinn, vmin_mu, vmax_mu\n",
    "    )\n",
    "    height, width, _ = first_frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(len(pinn_prod_frames)), desc=\"Creating video\"):\n",
    "            combined_frame = create_combined_frame(\n",
    "                pinn_prod_frames[i], sim_prod_frames[i], mu_pred_frames[i], mu_full_frames[i],\n",
    "                vmin_pinn, vmax_pinn, vmin_mu, vmax_mu\n",
    "            )\n",
    "            video_writer.write(cv2.cvtColor(combined_frame, cv2.COLOR_RGB2BGR))\n",
    "        video_writer.release()\n",
    "    except Exception as e:\n",
    "        video_writer.release()\n",
    "        raise RuntimeError(f\"Failed to create video: {e}\")\n",
    "\n",
    "    print(f\"Video saved at: {video_path}\")\n",
    "\n",
    "\n",
    "def generate_video(state, mu_full, model, x_vals, y_vals, t_vals, device, output_path):\n",
    "    \"\"\"\n",
    "    Generates a comparison video of predicted and actual values for states and mu fields.\n",
    "    \"\"\"\n",
    "    pinn_prod_frames, sim_prod_frames, mu_pred_frames, mu_full_frames = [], [], [], []\n",
    "\n",
    "    # 1) Expand the predicted mu to full shape once, shape (Nt, Nx, Ny)\n",
    "    mu_expanded = model.expand_myu_full(do_binarize=True, scale_255=True)\n",
    "\n",
    "    # 2) Loop over each time index\n",
    "    for i, t_val in enumerate(tqdm(t_vals, desc=\"Generating frames\")):\n",
    "        # Build a grid for the entire domain\n",
    "        X, Y = np.meshgrid(x_vals, y_vals)\n",
    "        XX, YY = X.ravel(), Y.ravel()\n",
    "        TT = np.full_like(XX, t_val)\n",
    "\n",
    "        x_test_t = torch.tensor(XX, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        y_test_t = torch.tensor(YY, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        t_test_t = torch.tensor(TT, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        # Predict A_r and A_i\n",
    "        A_r_pred, A_i_pred = model.predict(x_test_t, y_test_t, t_test_t)\n",
    "        A_r_pred_2d = A_r_pred.reshape(X.shape)\n",
    "        A_i_pred_2d = A_i_pred.reshape(X.shape)\n",
    "\n",
    "        # Calculate predicted product and true product\n",
    "        pinn_prod = A_r_pred_2d * A_i_pred_2d\n",
    "        sim_prod = state[i].real * state[i].imag\n",
    "\n",
    "        # Get the predicted and true mu values for this time slice\n",
    "        mu_pred_t = mu_expanded[i]  # Expanded predicted mu\n",
    "        mu_full_t = mu_full[i]  # Ground-truth mu\n",
    "\n",
    "        # Append frames\n",
    "        pinn_prod_frames.append(pinn_prod)\n",
    "        sim_prod_frames.append(sim_prod)\n",
    "        mu_pred_frames.append(mu_pred_t)\n",
    "        mu_full_frames.append(mu_full_t)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    pinn_prod_frames = np.array(pinn_prod_frames)\n",
    "    sim_prod_frames = np.array(sim_prod_frames)\n",
    "    mu_pred_frames = np.array(mu_pred_frames)\n",
    "    mu_full_frames = np.array(mu_full_frames)\n",
    "\n",
    "    # Create the video\n",
    "    create_video(output_path, pinn_prod_frames, sim_prod_frames, mu_pred_frames, mu_full_frames)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:07:06.589292Z",
     "start_time": "2025-01-23T20:07:06.563707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        for i in range(len(layers)-1):\n",
    "            modules.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            if i < len(layers)-2:\n",
    "                modules.append(nn.Softplus())\n",
    "        self.net = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class NPINN_PRO_MAX_TIMEBLOCK(nn.Module):\n",
    "    \"\"\"\n",
    "    A 'PINN' for the Complex Ginzburg–Landau equation, with both\n",
    "    - time downsampling: degrade_t\n",
    "    - x,y downsampling:  degrade_x, degrade_y\n",
    "    - We interpret each mu_small_raw in shape (Nt_down, Nx_down, Ny_down).\n",
    "\n",
    "    PDE: A_t = mu A + delta Lap(A) - |A|^2 A\n",
    "    where mu is a BINARY field => 0 or 1, but stored as raw -> threshold in get_myu_collocation.\n",
    "\n",
    "    'Time blocks': each coarse time index covers degrade_t frames in the full domain.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers,               # e.g. [3,64,64,2] for A_r, A_i\n",
    "        Nt, Nx, Ny,           # full domain sizes\n",
    "        Nx_down, Ny_down,     # smaller, downsampled domain for mu in x,y\n",
    "        dt, dx, dy,\n",
    "        degrade_x, degrade_y,\n",
    "        degrade_t,            # <--- NEW: factor for time downsampling\n",
    "        delta=0.01,\n",
    "        weight_pde=1.0,\n",
    "        device='cpu'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.delta  = delta\n",
    "        self.weight_pde = weight_pde\n",
    "\n",
    "        # Full domain\n",
    "        self.Nt, self.Nx, self.Ny = Nt, Nx, Ny\n",
    "        self.Nx_down, self.Ny_down = Nx_down, Ny_down\n",
    "        self.dt, self.dx, self.dy = dt, dx, dy\n",
    "        self.degrade_x, self.degrade_y = degrade_x, degrade_y\n",
    "        self.degrade_t = degrade_t\n",
    "\n",
    "        # The reduced domain size in time\n",
    "        # we assume Nt is divisible by degrade_t for simplicity\n",
    "        self.Nt_down = Nt // degrade_t\n",
    "\n",
    "        # 1) The neural net for A(x,y,t)\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "\n",
    "        # 2) The trainable mu_small: shape (Nt_down, Nx_down, Ny_down).\n",
    "        init = 0.3 * torch.randn(self.Nt_down, Nx_down, Ny_down)\n",
    "        self.mu_small_raw = nn.Parameter(init.to(device))\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "        return self.net_A(x, y, t)\n",
    "\n",
    "    def net_A(self, x, y, t):\n",
    "        inp = torch.cat([x,y,t], dim=1)\n",
    "        out = self.dnn(inp)\n",
    "        A_r = out[:,0:1]\n",
    "        A_i = out[:,1:2]\n",
    "        return A_r, A_i\n",
    "\n",
    "    def binarize_mu_small(self):\n",
    "        \"\"\"\n",
    "        Hard threshold the entire mu_small_raw -> 0 or 1 in place.\n",
    "        This is optional and breaks gradient flow.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            self.mu_small_raw.data = (self.mu_small_raw.data > 0.0).float()\n",
    "\n",
    "    def get_myu_collocation(self, x, y, t):\n",
    "        \"\"\"\n",
    "        (x,y,t) -> integer indices (i, j_down, k_down).\n",
    "        But for time, we do i = floor(t/dt), then i_down = floor(i/degrade_t).\n",
    "        Then threshold to 0/1.\n",
    "        \"\"\"\n",
    "        # Convert t-> i in [0..Nt-1]\n",
    "        i = (t[:,0] / self.dt).round().long().clamp(0, self.Nt-1)\n",
    "        # Then the coarse time index\n",
    "        i_down = (i // self.degrade_t).clamp(0, self.Nt_down-1)\n",
    "\n",
    "        j_down = (x[:,0] / (self.dx*self.degrade_x)).floor().long()\n",
    "        k_down = (y[:,0] / (self.dy*self.degrade_y)).floor().long()\n",
    "\n",
    "        j_down = j_down.clamp(0, self.Nx_down-1)\n",
    "        k_down = k_down.clamp(0, self.Ny_down-1)\n",
    "\n",
    "        mu_vals_raw = self.mu_small_raw[i_down, j_down, k_down]\n",
    "        # Binarize for PDE\n",
    "        mu_bin = (mu_vals_raw > 0.0).float()  # shape (batch,)\n",
    "        return mu_bin.view(-1,1)\n",
    "\n",
    "    def pde_residual(self, x, y, t):\n",
    "        A_r, A_i = self.net_A(x,y,t)\n",
    "        mu_vals = self.get_myu_collocation(x,y,t)\n",
    "\n",
    "        A_r_t = torch.autograd.grad(A_r, t,\n",
    "            grad_outputs=torch.ones_like(A_r),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_i_t = torch.autograd.grad(A_i, t,\n",
    "            grad_outputs=torch.ones_like(A_i),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        # wrt x\n",
    "        A_r_x = torch.autograd.grad(A_r, x,\n",
    "            grad_outputs=torch.ones_like(A_r),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_i_x = torch.autograd.grad(A_i, x,\n",
    "            grad_outputs=torch.ones_like(A_i),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        # wrt y\n",
    "        A_r_y = torch.autograd.grad(A_r, y,\n",
    "            grad_outputs=torch.ones_like(A_r),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_i_y = torch.autograd.grad(A_i, y,\n",
    "            grad_outputs=torch.ones_like(A_i),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        # second derivatives\n",
    "        A_r_xx = torch.autograd.grad(A_r_x, x,\n",
    "            grad_outputs=torch.ones_like(A_r_x),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_r_yy = torch.autograd.grad(A_r_y, y,\n",
    "            grad_outputs=torch.ones_like(A_r_y),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_i_xx = torch.autograd.grad(A_i_x, x,\n",
    "            grad_outputs=torch.ones_like(A_i_x),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_i_yy = torch.autograd.grad(A_i_y, y,\n",
    "            grad_outputs=torch.ones_like(A_i_y),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        lapA_r = A_r_xx + A_r_yy\n",
    "        lapA_i = A_i_xx + A_i_yy\n",
    "\n",
    "        A_abs2 = A_r**2 + A_i**2\n",
    "\n",
    "        f_r = A_r_t - mu_vals*A_r - self.delta*lapA_r + A_abs2*A_r\n",
    "        f_i = A_i_t - mu_vals*A_i - self.delta*lapA_i + A_abs2*A_i\n",
    "        return f_r, f_i\n",
    "\n",
    "    def loss_pde(self, x_eqs, y_eqs, t_eqs):\n",
    "        f_r, f_i = self.pde_residual(x_eqs, y_eqs, t_eqs)\n",
    "        return torch.mean(f_r**2 + f_i**2)\n",
    "\n",
    "    def loss_data(self, x_data, y_data, t_data, A_r_data, A_i_data):\n",
    "        A_r_pred, A_i_pred = self.net_A(x_data, y_data, t_data)\n",
    "        return torch.mean((A_r_pred - A_r_data)**2 + (A_i_pred - A_i_data)**2)\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        x_data, y_data, t_data, A_r_data, A_i_data,\n",
    "        x_eqs, y_eqs, t_eqs,\n",
    "        n_epochs=200000,\n",
    "        lr=1e-3,\n",
    "        model_name=\"MyModel\",\n",
    "        output_dir=\"./results\",\n",
    "        video_freq=10000,\n",
    "        state_exp=None,\n",
    "        myu_full_exp=None,\n",
    "        x_vals=None,\n",
    "        y_vals=None,\n",
    "        t_vals=None,\n",
    "        device=\"cpu\"\n",
    "    ):\n",
    "        import os\n",
    "        from datetime import datetime\n",
    "\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        model_folder = os.path.join(output_dir, model_name)\n",
    "        os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            pde_l  = self.loss_pde(x_eqs, y_eqs, t_eqs)\n",
    "            data_l = self.loss_data(x_data, y_data, t_data, A_r_data, A_i_data)\n",
    "            loss   = data_l + self.weight_pde*pde_l\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(f\"Epoch={epoch}, total={loss.item():.4e}, data={data_l.item():.4e}, PDE={pde_l.item():.4e}\")\n",
    "\n",
    "            if (epoch % video_freq==0 and epoch>0):\n",
    "                ckpt_path = os.path.join(model_folder, f\"{model_name}_epoch_{epoch}.pt\")\n",
    "                torch.save(self.state_dict(), ckpt_path)\n",
    "                print(f\"Checkpoint saved at {ckpt_path}\")\n",
    "\n",
    "                # optional video\n",
    "                if (state_exp is not None) and (myu_full_exp is not None) \\\n",
    "                   and (x_vals is not None) and (y_vals is not None) and (t_vals is not None):\n",
    "                    vid_name = f\"{model_name}_epoch_{epoch}_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "                    video_folder = os.path.join(model_folder, \"videos\")\n",
    "                    os.makedirs(video_folder, exist_ok=True)\n",
    "\n",
    "                    video_path = os.path.join(video_folder, vid_name)\n",
    "                    generate_video(\n",
    "                        state_exp,\n",
    "                        myu_full_exp,\n",
    "                        self,\n",
    "                        x_vals, y_vals, t_vals,\n",
    "                        device=device,\n",
    "                        output_path=video_path\n",
    "                    )\n",
    "\n",
    "        final_ckpt = os.path.join(model_folder, f\"{model_name}_final_{n_epochs}.pt\")\n",
    "        torch.save(self.state_dict(), final_ckpt)\n",
    "        print(f\"Final checkpoint saved at {final_ckpt}\\nTraining done.\\n\")\n",
    "\n",
    "    def expand_myu_full(self, do_binarize=True, scale_255=False):\n",
    "        \"\"\"\n",
    "        Expand mu_small_raw shape = (Nt_down, Nx_down, Ny_down)\n",
    "        to full shape (Nt, Nx, Ny) by:\n",
    "         1) repeat_interleave along time dim by degrade_t\n",
    "         2) repeat_interleave along x,y dims by degrade_x, degrade_y\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            mu_raw = self.mu_small_raw.detach()  # shape (Nt_down, Nx_down, Ny_down)\n",
    "\n",
    "            if do_binarize:\n",
    "                mu_bin = (mu_raw>0.0).float()\n",
    "            else:\n",
    "                mu_bin = mu_raw\n",
    "\n",
    "            # time expansion\n",
    "            mu_time = mu_bin.repeat_interleave(self.degrade_t, dim=0)\n",
    "            # shape => (Nt_down*degrade_t, Nx_down, Ny_down) = (Nt, Nx_down, Ny_down)\n",
    "\n",
    "            # expand in x,y\n",
    "            mu_full_x = mu_time.repeat_interleave(self.degrade_x, dim=1)\n",
    "            mu_full_xy = mu_full_x.repeat_interleave(self.degrade_y, dim=2)\n",
    "\n",
    "            if scale_255:\n",
    "                mu_full_xy = mu_full_xy * 255.0\n",
    "\n",
    "            return mu_full_xy.cpu().numpy()\n",
    "\n",
    "    def predict(self, x, y, t):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            A_r, A_i = self.net_A(x, y, t)\n",
    "        return A_r.cpu().numpy(), A_i.cpu().numpy()\n"
   ],
   "id": "cf8606b0059d61f9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:24:35.163320Z",
     "start_time": "2025-01-23T20:24:34.451819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state = np.load(\"../data/test_new/states_processed_cropped.npy\")\n",
    "myu_full = np.load(\"../data/test_new/myus_binarized_processed_cropped.npy\")\n",
    "\n",
    "print(\"State shape:\", state.shape, state.dtype)  # (350,530,880), complex128\n",
    "print(\"Myu shape:  \", myu_full.shape, myu_full.dtype)  # (350,530,880), uint16\n",
    "\n",
    "A_r_data = state.real\n",
    "A_i_data = state.imag\n",
    "\n",
    "Nt, Nx, Ny = state.shape\n",
    "dt, dx, dy = 0.05, 0.3, 0.3  # Example values\n",
    "Nx_down, Ny_down = 10, 10\n",
    "degrade_x = Nx // Nx_down  # 530//10=53\n",
    "degrade_y = Ny // Ny_down  # 880//10=88"
   ],
   "id": "cf10da46cdc46be9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape: (350, 530, 880) complex128\n",
      "Myu shape:   (350, 530, 880) uint16\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:07:23.279755Z",
     "start_time": "2025-01-23T20:07:21.435802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = NPINN_PRO_MAX_TIMEBLOCK(\n",
    "    layers=[3,64,64,2],\n",
    "    Nt=Nt, Nx=Nx, Ny=Ny,\n",
    "    Nx_down=Nx_down, Ny_down=Ny_down,\n",
    "    dt=dt, dx=dx, dy=dy,\n",
    "    degrade_x=degrade_x, degrade_y=degrade_y,\n",
    "    delta=0.01,\n",
    "    weight_pde=0.1,\n",
    "    device='cuda',\n",
    "    degrade_t=50\n",
    ")\n",
    "model.to('cuda')"
   ],
   "id": "bf070e80452d665c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NPINN_PRO_MAX_TIMEBLOCK(\n",
       "  (dnn): DNN(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "      (1): Softplus(beta=1.0, threshold=20.0)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Softplus(beta=1.0, threshold=20.0)\n",
       "      (4): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:24:38.417365Z",
     "start_time": "2025-01-23T20:24:38.406324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_data = 20000\n",
    "idx_t = np.random.randint(0, Nt, size=n_data)\n",
    "idx_x = np.random.randint(0, Nx, size=n_data)\n",
    "idx_y = np.random.randint(0, Ny, size=n_data)\n",
    "\n",
    "t_vals = np.arange(Nt) * dt\n",
    "x_vals = np.arange(Nx) * dx\n",
    "y_vals = np.arange(Ny) * dy\n",
    "\n",
    "t_data_np = t_vals[idx_t]\n",
    "x_data_np = x_vals[idx_x]\n",
    "y_data_np = y_vals[idx_y]\n",
    "\n",
    "Ar_data_np = A_r_data[idx_t, idx_x, idx_y]\n",
    "Ai_data_np = A_i_data[idx_t, idx_x, idx_y]\n",
    "\n",
    "import torch\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "x_data_t = torch.tensor(x_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "y_data_t = torch.tensor(y_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "t_data_t = torch.tensor(t_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "Ar_data_t = torch.tensor(Ar_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "Ai_data_t = torch.tensor(Ai_data_np, dtype=torch.float32, device=device).view(-1, 1)\n",
    "\n",
    "n_coll = 20000\n",
    "t_eqs_np = np.random.uniform(0, t_vals[-1], size=n_coll)\n",
    "x_eqs_np = np.random.uniform(0, x_vals[-1], size=n_coll)\n",
    "y_eqs_np = np.random.uniform(0, y_vals[-1], size=n_coll)\n",
    "\n",
    "x_eqs_t = torch.tensor(x_eqs_np, dtype=torch.float32, device=device, requires_grad=True).view(-1, 1)\n",
    "y_eqs_t = torch.tensor(y_eqs_np, dtype=torch.float32, device=device, requires_grad=True).view(-1, 1)\n",
    "t_eqs_t = torch.tensor(t_eqs_np, dtype=torch.float32, device=device, requires_grad=True).view(-1, 1)"
   ],
   "id": "7f1ed6de9b1fa169",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:24:41.000816Z",
     "start_time": "2025-01-23T20:24:40.993562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "        )\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(x + self.layers(x))\n",
    "\n",
    "class ImprovedDNN(nn.Module):\n",
    "    def __init__(self, layers, n_res_blocks=3):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "        # Input projection\n",
    "        modules.append(nn.Linear(layers[0], layers[1]))\n",
    "        modules.append(nn.BatchNorm1d(layers[1]))\n",
    "        modules.append(nn.GELU())\n",
    "\n",
    "        # Middle layers with residual blocks\n",
    "        mid_dim = layers[1]\n",
    "        for _ in range(n_res_blocks):\n",
    "            modules.append(ResBlock(mid_dim))\n",
    "\n",
    "        # Additional dense layers with increasing width\n",
    "        for i in range(1, len(layers)-2):\n",
    "            modules.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(layers[i+1]))\n",
    "            modules.append(nn.GELU())\n",
    "\n",
    "        # Output projection\n",
    "        modules.append(nn.Linear(layers[-2], layers[-1]))\n",
    "\n",
    "        self.net = nn.Sequential(*modules)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "4ea0c6c0626212ee",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:24:41.588317Z",
     "start_time": "2025-01-23T20:24:41.566428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NPINN_PRO_MAX_TIMEBLOCK_V2(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers,\n",
    "        Nt, Nx, Ny,\n",
    "        Nx_down, Ny_down,\n",
    "        dt, dx, dy,\n",
    "        degrade_x, degrade_y,\n",
    "        degrade_t,\n",
    "        delta=0.01,\n",
    "        weight_pde=1.0,\n",
    "        device='cpu'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.delta = delta\n",
    "        self.weight_pde = weight_pde\n",
    "\n",
    "        # Domain parameters (same as original)\n",
    "        self.Nt, self.Nx, self.Ny = Nt, Nx, Ny\n",
    "        self.Nx_down, self.Ny_down = Nx_down, Ny_down\n",
    "        self.dt, self.dx, self.dy = dt, dx, dy\n",
    "        self.degrade_x, self.degrade_y = degrade_x, degrade_y\n",
    "        self.degrade_t = degrade_t\n",
    "        self.Nt_down = Nt // degrade_t\n",
    "\n",
    "        # Improved neural network for A(x,y,t)\n",
    "        self.dnn = ImprovedDNN(layers, n_res_blocks=3).to(device)\n",
    "\n",
    "        # The trainable mu_small (same as original)\n",
    "        init = 0.3 * torch.randn(self.Nt_down, Nx_down, Ny_down)\n",
    "        self.mu_small_raw = nn.Parameter(init.to(device))\n",
    "\n",
    "        # Spatial frequency encodings\n",
    "        self.register_buffer('freq_x', torch.linspace(0, 10, layers[0]))\n",
    "        self.register_buffer('freq_y', torch.linspace(0, 10, layers[0]))\n",
    "        self.register_buffer('freq_t', torch.linspace(0, 10, layers[0]))\n",
    "\n",
    "    def positional_encoding(self, x, y, t):\n",
    "        \"\"\"Add spatial frequency encodings to the input\"\"\"\n",
    "        enc_x = torch.sin(x * self.freq_x[None, :])\n",
    "        enc_y = torch.sin(y * self.freq_y[None, :])\n",
    "        enc_t = torch.sin(t * self.freq_t[None, :])\n",
    "        return (enc_x + enc_y + enc_t) / 3.0\n",
    "\n",
    "    def net_A(self, x, y, t):\n",
    "        # Concatenate inputs and add positional encoding\n",
    "        inp_raw = torch.cat([x, y, t], dim=1)\n",
    "        pos_enc = self.positional_encoding(x, y, t)\n",
    "        inp = inp_raw + pos_enc\n",
    "\n",
    "        out = self.dnn(inp)\n",
    "        return out[:, 0:1], out[:, 1:2]\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "        return self.net_A(x, y, t)\n",
    "\n",
    "    def binarize_mu_small(self):\n",
    "        \"\"\"\n",
    "        Hard threshold the entire mu_small_raw -> 0 or 1 in place.\n",
    "        This is optional and breaks gradient flow.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            self.mu_small_raw.data = (self.mu_small_raw.data > 0.0).float()\n",
    "\n",
    "    def get_myu_collocation(self, x, y, t):\n",
    "        \"\"\"\n",
    "        (x,y,t) -> integer indices (i, j_down, k_down).\n",
    "        But for time, we do i = floor(t/dt), then i_down = floor(i/degrade_t).\n",
    "        Then threshold to 0/1.\n",
    "        \"\"\"\n",
    "        # Convert t-> i in [0..Nt-1]\n",
    "        i = (t[:,0] / self.dt).round().long().clamp(0, self.Nt-1)\n",
    "        # Then the coarse time index\n",
    "        i_down = (i // self.degrade_t).clamp(0, self.Nt_down-1)\n",
    "\n",
    "        j_down = (x[:,0] / (self.dx*self.degrade_x)).floor().long()\n",
    "        k_down = (y[:,0] / (self.dy*self.degrade_y)).floor().long()\n",
    "\n",
    "        j_down = j_down.clamp(0, self.Nx_down-1)\n",
    "        k_down = k_down.clamp(0, self.Ny_down-1)\n",
    "\n",
    "        mu_vals_raw = self.mu_small_raw[i_down, j_down, k_down]\n",
    "        # Binarize for PDE\n",
    "        mu_bin = (mu_vals_raw > 0.0).float()  # shape (batch,)\n",
    "        return mu_bin.view(-1,1)\n",
    "\n",
    "    def pde_residual(self, x, y, t):\n",
    "        A_r, A_i = self.net_A(x,y,t)\n",
    "        mu_vals = self.get_myu_collocation(x,y,t)\n",
    "\n",
    "        A_r_t = torch.autograd.grad(A_r, t,\n",
    "            grad_outputs=torch.ones_like(A_r),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_i_t = torch.autograd.grad(A_i, t,\n",
    "            grad_outputs=torch.ones_like(A_i),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        # wrt x\n",
    "        A_r_x = torch.autograd.grad(A_r, x,\n",
    "            grad_outputs=torch.ones_like(A_r),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_i_x = torch.autograd.grad(A_i, x,\n",
    "            grad_outputs=torch.ones_like(A_i),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        # wrt y\n",
    "        A_r_y = torch.autograd.grad(A_r, y,\n",
    "            grad_outputs=torch.ones_like(A_r),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_i_y = torch.autograd.grad(A_i, y,\n",
    "            grad_outputs=torch.ones_like(A_i),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        # second derivatives\n",
    "        A_r_xx = torch.autograd.grad(A_r_x, x,\n",
    "            grad_outputs=torch.ones_like(A_r_x),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_r_yy = torch.autograd.grad(A_r_y, y,\n",
    "            grad_outputs=torch.ones_like(A_r_y),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_i_xx = torch.autograd.grad(A_i_x, x,\n",
    "            grad_outputs=torch.ones_like(A_i_x),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "        A_i_yy = torch.autograd.grad(A_i_y, y,\n",
    "            grad_outputs=torch.ones_like(A_i_y),\n",
    "            create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        lapA_r = A_r_xx + A_r_yy\n",
    "        lapA_i = A_i_xx + A_i_yy\n",
    "\n",
    "        A_abs2 = A_r**2 + A_i**2\n",
    "\n",
    "        f_r = A_r_t - mu_vals*A_r - self.delta*lapA_r + A_abs2*A_r\n",
    "        f_i = A_i_t - mu_vals*A_i - self.delta*lapA_i + A_abs2*A_i\n",
    "        return f_r, f_i\n",
    "\n",
    "    def loss_pde(self, x_eqs, y_eqs, t_eqs):\n",
    "        f_r, f_i = self.pde_residual(x_eqs, y_eqs, t_eqs)\n",
    "        return torch.mean(f_r**2 + f_i**2)\n",
    "\n",
    "    def gradient_penalty(self, x, y, t):\n",
    "        \"\"\"Additional regularization for derivatives\"\"\"\n",
    "        A_r, A_i = self.net_A(x, y, t)\n",
    "\n",
    "        gradients_r = torch.autograd.grad(\n",
    "            A_r.sum(), x, create_graph=True, retain_graph=True)[0]\n",
    "        gradients_i = torch.autograd.grad(\n",
    "            A_i.sum(), x, create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        return (gradients_r.pow(2).sum() + gradients_i.pow(2).sum()) / x.shape[0]\n",
    "\n",
    "    def loss_data(self, x_data, y_data, t_data, A_r_data, A_i_data):\n",
    "        A_r_pred, A_i_pred = self.net_A(x_data, y_data, t_data)\n",
    "\n",
    "        # L2 loss\n",
    "        l2_loss = torch.mean((A_r_pred - A_r_data)**2 + (A_i_pred - A_i_data)**2)\n",
    "\n",
    "        # Add L1 loss for better stability\n",
    "        l1_loss = torch.mean(torch.abs(A_r_pred - A_r_data) + torch.abs(A_i_pred - A_i_data))\n",
    "\n",
    "        return l2_loss + 0.1 * l1_loss\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        x_data, y_data, t_data, A_r_data, A_i_data,\n",
    "        x_eqs, y_eqs, t_eqs,\n",
    "        n_epochs=200000,\n",
    "        lr=1e-3,\n",
    "        batch_size=1024,\n",
    "        model_name=\"MyModel\",\n",
    "        output_dir=\"./results\",\n",
    "        video_freq=10000,\n",
    "        state_exp=None,\n",
    "        myu_full_exp=None,\n",
    "        x_vals=None,\n",
    "        y_vals=None,\n",
    "        t_vals=None,\n",
    "        device=\"cpu\"\n",
    "    ):\n",
    "        import os\n",
    "        from datetime import datetime\n",
    "        from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_dataset = TensorDataset(x_data, y_data, t_data, A_r_data, A_i_data)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Collocation points dataloader\n",
    "        coll_dataset = TensorDataset(x_eqs, y_eqs, t_eqs)\n",
    "        coll_loader = DataLoader(coll_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Optimizer and scheduler\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=lr,\n",
    "            epochs=n_epochs,\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            pct_start=0.1,\n",
    "            div_factor=25.0\n",
    "        )\n",
    "\n",
    "        # Gradient clipping\n",
    "        max_grad_norm = 1.0\n",
    "\n",
    "        model_folder = os.path.join(output_dir, model_name)\n",
    "        os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        patience = 10  # epochs for early stopping\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            total_loss = 0\n",
    "            total_data_loss = 0\n",
    "            total_pde_loss = 0\n",
    "\n",
    "            for (x_d, y_d, t_d, ar_d, ai_d), (x_e, y_e, t_e) in zip(train_loader, coll_loader):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Data loss\n",
    "                data_loss = self.loss_data(x_d, y_d, t_d, ar_d, ai_d)\n",
    "\n",
    "                # PDE loss\n",
    "                pde_loss = self.loss_pde(x_e, y_e, t_e)\n",
    "\n",
    "                # Gradient penalty\n",
    "                grad_penalty = self.gradient_penalty(x_e, y_e, t_e)\n",
    "\n",
    "                # Total loss\n",
    "                loss = data_loss + self.weight_pde * pde_loss + 0.01 * grad_penalty\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.parameters(), max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                total_data_loss += data_loss.item()\n",
    "                total_pde_loss += pde_loss.item()\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            avg_data_loss = total_data_loss / len(train_loader)\n",
    "            avg_pde_loss = total_pde_loss / len(train_loader)\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(f\"Epoch={epoch}, total={avg_loss:.4e}, data={avg_data_loss:.4e}, PDE={avg_pde_loss:.4e}\")\n",
    "\n",
    "                # Early stopping check\n",
    "                if avg_loss < best_loss:\n",
    "                    best_loss = avg_loss\n",
    "                    patience_counter = 0\n",
    "                    # Save best model\n",
    "                    torch.save(self.state_dict(), os.path.join(model_folder, f\"{model_name}_best.pt\"))\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(\"Early stopping triggered\")\n",
    "                        break\n",
    "\n",
    "            # Rest of the training loop (checkpointing, video generation) remains the same\n",
    "            if (epoch % video_freq == 0 and epoch > 0):\n",
    "                ckpt_path = os.path.join(model_folder, f\"{model_name}_epoch_{epoch}.pt\")\n",
    "                torch.save(self.state_dict(), ckpt_path)\n",
    "                print(f\"Checkpoint saved at {ckpt_path}\")\n",
    "\n",
    "                if all(x is not None for x in [state_exp, myu_full_exp, x_vals, y_vals, t_vals]):\n",
    "                    vid_name = f\"{model_name}_epoch_{epoch}_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "                    video_folder = os.path.join(model_folder, \"videos\")\n",
    "                    os.makedirs(video_folder, exist_ok=True)\n",
    "                    video_path = os.path.join(video_folder, vid_name)\n",
    "                    generate_video(state_exp, myu_full_exp, self, x_vals, y_vals, t_vals, device=device, output_path=video_path)\n",
    "\n",
    "        final_ckpt = os.path.join(model_folder, f\"{model_name}_final_{n_epochs}.pt\")\n",
    "        torch.save(self.state_dict(), final_ckpt)\n",
    "        print(f\"Final checkpoint saved at {final_ckpt}\\nTraining done.\\n\")\n",
    "\n",
    "    def expand_myu_full(self, do_binarize=True, scale_255=False):\n",
    "        \"\"\"\n",
    "        Expand mu_small_raw shape = (Nt_down, Nx_down, Ny_down)\n",
    "        to full shape (Nt, Nx, Ny) by:\n",
    "         1) repeat_interleave along time dim by degrade_t\n",
    "         2) repeat_interleave along x,y dims by degrade_x, degrade_y\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            mu_raw = self.mu_small_raw.detach()  # shape (Nt_down, Nx_down, Ny_down)\n",
    "\n",
    "            if do_binarize:\n",
    "                mu_bin = (mu_raw>0.0).float()\n",
    "            else:\n",
    "                mu_bin = mu_raw\n",
    "\n",
    "            # time expansion\n",
    "            mu_time = mu_bin.repeat_interleave(self.degrade_t, dim=0)\n",
    "            # shape => (Nt_down*degrade_t, Nx_down, Ny_down) = (Nt, Nx_down, Ny_down)\n",
    "\n",
    "            # expand in x,y\n",
    "            mu_full_x = mu_time.repeat_interleave(self.degrade_x, dim=1)\n",
    "            mu_full_xy = mu_full_x.repeat_interleave(self.degrade_y, dim=2)\n",
    "\n",
    "            if scale_255:\n",
    "                mu_full_xy = mu_full_xy * 255.0\n",
    "\n",
    "            return mu_full_xy.cpu().numpy()\n",
    "\n",
    "    def predict(self, x, y, t):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            A_r, A_i = self.net_A(x, y, t)\n",
    "        return A_r.cpu().numpy(), A_i.cpu().numpy()"
   ],
   "id": "9a8b53f31c02e14e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:26:11.545644Z",
     "start_time": "2025-01-23T20:26:11.533899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First initialize the improved model\n",
    "model = NPINN_PRO_MAX_TIMEBLOCK_V2(\n",
    "    layers=[3, 128, 256, 256, 128, 2],  # Deeper and wider architecture\n",
    "    Nt=Nt, Nx=Nx, Ny=Ny,\n",
    "    Nx_down=Nx_down, Ny_down=Ny_down,\n",
    "    dt=dt, dx=dx, dy=dy,\n",
    "    degrade_x=degrade_x, degrade_y=degrade_y,\n",
    "    delta=0.01,\n",
    "    weight_pde=0.1,\n",
    "    device='cuda',\n",
    "    degrade_t=50\n",
    ")\n",
    "model.to('cuda')"
   ],
   "id": "d00e51be05f74954",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NPINN_PRO_MAX_TIMEBLOCK_V2(\n",
       "  (dnn): ImprovedDNN(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ResBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "      (5): ResBlock(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "      (6): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): GELU(approximate='none')\n",
       "      (9): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): GELU(approximate='none')\n",
       "      (12): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): GELU(approximate='none')\n",
       "      (15): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T23:00:46.687908Z",
     "start_time": "2025-01-23T20:26:58.161672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Then train with these parameters\n",
    "model.train_model(\n",
    "    x_data=x_data_t,\n",
    "    y_data=y_data_t,\n",
    "    t_data=t_data_t,\n",
    "    A_r_data=Ar_data_t,\n",
    "    A_i_data=Ai_data_t,\n",
    "    x_eqs=x_eqs_t,\n",
    "    y_eqs=y_eqs_t,\n",
    "    t_eqs=t_eqs_t,\n",
    "    n_epochs=200001,\n",
    "    lr=1e-3,\n",
    "    batch_size=2048,  # Increased batch size for better stability\n",
    "    model_name=\"TimeBlockerV2_Test\",\n",
    "    output_dir=\"./results\",\n",
    "    video_freq=1000,\n",
    "    state_exp=state,  # for generating comparison video\n",
    "    myu_full_exp=myu_full,\n",
    "    x_vals=x_vals,\n",
    "    y_vals=y_vals,\n",
    "    t_vals=t_vals,\n",
    "    device='cuda'\n",
    ")"
   ],
   "id": "130d3c5b276bc778",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, total=3.4745e-01, data=3.4321e-01, PDE=4.1571e-02\n",
      "Epoch=500, total=1.6011e-01, data=1.5217e-01, PDE=7.8240e-02\n",
      "Epoch=1000, total=1.4463e-01, data=1.3657e-01, PDE=7.9273e-02\n",
      "Checkpoint saved at ./results\\TimeBlockerV2_Test\\TimeBlockerV2_Test_epoch_1000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating frames: 100%|██████████| 350/350 [00:48<00:00,  7.22it/s]\n",
      "Creating video: 100%|██████████| 350/350 [01:37<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at: ./results\\TimeBlockerV2_Test\\videos\\TimeBlockerV2_Test_epoch_1000_20250124023846\\output_video_20250124023936.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Then train with these parameters\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mA_r_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAr_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mA_i_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAi_data_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_eqs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_eqs_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_eqs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_eqs_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_eqs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_eqs_t\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200001\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2048\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Increased batch size for better stability\u001B[39;49;00m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTimeBlockerV2_Test\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./results\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvideo_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_exp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# for generating comparison video\u001B[39;49;00m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmyu_full_exp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmyu_full\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_vals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_vals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_vals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_vals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_vals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_vals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[0;32m     23\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[13], line 220\u001B[0m, in \u001B[0;36mNPINN_PRO_MAX_TIMEBLOCK_V2.train_model\u001B[1;34m(self, x_data, y_data, t_data, A_r_data, A_i_data, x_eqs, y_eqs, t_eqs, n_epochs, lr, batch_size, model_name, output_dir, video_freq, state_exp, myu_full_exp, x_vals, y_vals, t_vals, device)\u001B[0m\n\u001B[0;32m    217\u001B[0m total_data_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    218\u001B[0m total_pde_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 220\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_d\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_d\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_d\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mar_d\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mai_d\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_e\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_e\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_e\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoll_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Data loss\u001B[39;49;00m\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:211\u001B[0m, in \u001B[0;36mTensorDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[1;32m--> 211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(tensor[index] \u001B[38;5;28;01mfor\u001B[39;00m tensor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtensors)\n",
      "File \u001B[1;32m~\\Desktop\\gl_pinn-final\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:211\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[1;32m--> 211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(tensor[index] \u001B[38;5;28;01mfor\u001B[39;00m tensor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtensors)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "987b750603544d34"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
