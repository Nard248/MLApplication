{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def prepare_ndarray_frame(data, vmin, vmax, cmap='viridis', title=\"\"):\n",
    "    \"\"\"Prepares a frame from a numpy array for video by plotting it and returning the image as an ndarray.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    im = ax.imshow(data, cmap=cmap, origin='lower', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.axis('off')\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    image = np.frombuffer(fig.canvas.buffer_rgba(), dtype='uint8').reshape(height, width, 4)\n",
    "    plt.close(fig)\n",
    "    return image[:, :, :3]\n",
    "\n",
    "def create_combined_frame(pinn_prod, sim_prod, mu_pred, mu_full, vmin_pinn, vmax_pinn, vmin_mu, vmax_mu):\n",
    "    \"\"\"Creates a combined frame showing predicted and original states and mu-fields.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "    axes[0].imshow(pinn_prod, cmap=\"viridis\", origin=\"lower\", vmin=vmin_pinn, vmax=vmax_pinn)\n",
    "    axes[0].set_title(\"PINN: Real × Imag\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(sim_prod, cmap=\"viridis\", origin=\"lower\", vmin=vmin_pinn, vmax=vmax_pinn)\n",
    "    axes[1].set_title(\"Sim: Real × Imag\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(mu_pred, cmap=\"viridis\", origin=\"lower\", vmin=vmin_mu, vmax=vmax_mu)\n",
    "    axes[2].set_title(\"Predicted μ\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    axes[3].imshow(mu_full, cmap=\"viridis\", origin=\"lower\", vmin=vmin_mu, vmax=vmax_mu)\n",
    "    axes[3].set_title(\"Original μ\")\n",
    "    axes[3].axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    image = np.frombuffer(fig.canvas.buffer_rgba(), dtype='uint8').reshape(height, width, 4)\n",
    "    plt.close(fig)\n",
    "    return image[:, :, :3]  # Return only RGB\n",
    "\n",
    "\n",
    "def create_video(output_path, pinn_prod_frames, sim_prod_frames, mu_pred_frames, mu_full_frames, fps=30):\n",
    "    \"\"\"Creates a video combining frames.\"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    video_path = os.path.join(output_path, f\"output_video_{datetime.now().strftime('%Y%m%d%H%M%S')}.mp4\")\n",
    "    vmin_pinn, vmax_pinn = np.min(pinn_prod_frames), np.max(pinn_prod_frames)\n",
    "    vmin_mu, vmax_mu = np.min(mu_pred_frames), np.max(mu_pred_frames)\n",
    "\n",
    "    first_frame = create_combined_frame(\n",
    "        pinn_prod_frames[0], sim_prod_frames[0], mu_pred_frames[0], mu_full_frames[0],\n",
    "        vmin_pinn, vmax_pinn, vmin_mu, vmax_mu\n",
    "    )\n",
    "    height, width, _ = first_frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(len(pinn_prod_frames)), desc=\"Creating video\"):\n",
    "            combined_frame = create_combined_frame(\n",
    "                pinn_prod_frames[i], sim_prod_frames[i], mu_pred_frames[i], mu_full_frames[i],\n",
    "                vmin_pinn, vmax_pinn, vmin_mu, vmax_mu\n",
    "            )\n",
    "            video_writer.write(cv2.cvtColor(combined_frame, cv2.COLOR_RGB2BGR))\n",
    "        video_writer.release()\n",
    "    except Exception as e:\n",
    "        video_writer.release()\n",
    "        raise RuntimeError(f\"Failed to create video: {e}\")\n",
    "\n",
    "    print(f\"Video saved at: {video_path}\")\n",
    "\n",
    "\n",
    "def generate_video(state, mu_full, model, x_vals, y_vals, t_vals, device, output_path):\n",
    "    \"\"\"\n",
    "    Generates a comparison video of predicted and actual values for states and mu fields.\n",
    "    \"\"\"\n",
    "    pinn_prod_frames, sim_prod_frames, mu_pred_frames, mu_full_frames = [], [], [], []\n",
    "\n",
    "    # 1) Expand the predicted mu to full shape once, shape (Nt, Nx, Ny)\n",
    "    mu_expanded = model.expand_myu_full(do_binarize=True, scale_255=True)\n",
    "\n",
    "    # 2) Loop over each time index\n",
    "    for i, t_val in enumerate(tqdm(t_vals, desc=\"Generating frames\")):\n",
    "        # Build a grid for the entire domain\n",
    "        X, Y = np.meshgrid(x_vals, y_vals)\n",
    "        XX, YY = X.ravel(), Y.ravel()\n",
    "        TT = np.full_like(XX, t_val)\n",
    "\n",
    "        x_test_t = torch.tensor(XX, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        y_test_t = torch.tensor(YY, dtype=torch.float32).view(-1, 1).to(device)\n",
    "        t_test_t = torch.tensor(TT, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        # Predict A_r and A_i\n",
    "        A_r_pred, A_i_pred = model.predict(x_test_t, y_test_t, t_test_t)\n",
    "        A_r_pred_2d = A_r_pred.reshape(X.shape)\n",
    "        A_i_pred_2d = A_i_pred.reshape(X.shape)\n",
    "\n",
    "        # Calculate predicted product and true product\n",
    "        pinn_prod = A_r_pred_2d * A_i_pred_2d\n",
    "        sim_prod = state[i].real * state[i].imag\n",
    "\n",
    "        # Get the predicted and true mu values for this time slice\n",
    "        mu_pred_t = mu_expanded[i]  # Expanded predicted mu\n",
    "        mu_full_t = mu_full[i]  # Ground-truth mu\n",
    "\n",
    "        # Append frames\n",
    "        pinn_prod_frames.append(pinn_prod)\n",
    "        sim_prod_frames.append(sim_prod)\n",
    "        mu_pred_frames.append(mu_pred_t)\n",
    "        mu_full_frames.append(mu_full_t)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    pinn_prod_frames = np.array(pinn_prod_frames)\n",
    "    sim_prod_frames = np.array(sim_prod_frames)\n",
    "    mu_pred_frames = np.array(mu_pred_frames)\n",
    "    mu_full_frames = np.array(mu_full_frames)\n",
    "\n",
    "    # Create the video\n",
    "    create_video(output_path, pinn_prod_frames, sim_prod_frames, mu_pred_frames, mu_full_frames)"
   ],
   "id": "c040fd1396b9b33d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A CNN that predicts (A_r, A_i) from spatial-temporal inputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_layers=4, base_filters=32):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: Number of input channels (e.g., 1 for `t` or `mu` input).\n",
    "            out_channels: Number of output channels (e.g., 2 for `A_r, A_i`).\n",
    "            num_layers: Number of convolutional layers.\n",
    "            base_filters: Number of filters in the first layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Conv2d(in_channels, base_filters, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        # Intermediate layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(nn.Conv2d(base_filters, base_filters, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Conv2d(base_filters, out_channels, kernel_size=3, padding=1))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, in_channels, Nx, Ny).\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, out_channels, Nx, Ny).\n",
    "        \"\"\"\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "class NPINN_CNN_TIMEBLOCK(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,         # Input channels (e.g., 3 for (x, y, t))\n",
    "        out_channels,        # Output channels (e.g., 2 for A_r, A_i)\n",
    "        Nt, Nx, Ny,\n",
    "        Nx_down, Ny_down,    # Downsampled domain sizes for mu\n",
    "        dt, dx, dy,\n",
    "        degrade_x, degrade_y,\n",
    "        degrade_t,\n",
    "        delta=0.01,\n",
    "        weight_pde=1.0,\n",
    "        device=\"cpu\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.delta = delta\n",
    "        self.weight_pde = weight_pde\n",
    "\n",
    "        self.Nt, self.Nx, self.Ny = Nt, Nx, Ny\n",
    "        self.Nx_down, self.Ny_down = Nx_down, Ny_down\n",
    "        self.dt, self.dx, self.dy = dt, dx, dy\n",
    "        self.degrade_x, self.degrade_y = degrade_x, degrade_y\n",
    "        self.degrade_t = degrade_t\n",
    "        self.Nt_down = Nt // degrade_t\n",
    "\n",
    "        # CNN for predicting A(x, y, t)\n",
    "        self.cnn = CNN(\n",
    "            in_channels=in_channels,  # 3 for (x, y, t)\n",
    "            out_channels=out_channels\n",
    "        ).to(device)\n",
    "\n",
    "        # Trainable mu_small (reduced domain in time and space)\n",
    "        init = 0.3 * torch.randn(self.Nt_down, Nx_down, Ny_down)\n",
    "        self.mu_small_raw = nn.Parameter(init.to(device))\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "        return self.net_A(x, y, t)\n",
    "\n",
    "    def net_A(self, x, y, t):\n",
    "        # Concatenate (x, y, t) along channel dimension and reshape for CNN\n",
    "        batch_size = x.shape[0]\n",
    "        inputs = torch.stack([x, y, t], dim=1)  # Shape: [batch_size, 3, 1, 1]\n",
    "        inputs = inputs.view(batch_size, 3, 1, 1)  # Ensure 4D for CNN\n",
    "        outputs = self.cnn(inputs)\n",
    "        A_r, A_i = outputs[:, 0:1, 0, 0], outputs[:, 1:2, 0, 0]\n",
    "        return A_r, A_i\n",
    "\n",
    "    def get_myu_collocation(self, x, y, t):\n",
    "        i = (t[:, 0] / self.dt).round().long().clamp(0, self.Nt - 1)\n",
    "        i_down = (i // self.degrade_t).clamp(0, self.Nt_down - 1)\n",
    "        j_down = (x[:, 0] / (self.dx * self.degrade_x)).floor().long().clamp(0, self.Nx_down - 1)\n",
    "        k_down = (y[:, 0] / (self.dy * self.degrade_y)).floor().long().clamp(0, self.Ny_down - 1)\n",
    "        mu_vals_raw = self.mu_small_raw[i_down, j_down, k_down]\n",
    "        return mu_vals_raw.view(-1, 1)\n",
    "\n",
    "    def pde_residual(self, x, y, t):\n",
    "        A_r, A_i = self.net_A(x, y, t)\n",
    "        mu_vals = self.get_myu_collocation(x, y, t)\n",
    "\n",
    "        A_r_t = torch.autograd.grad(A_r, t, grad_outputs=torch.ones_like(A_r),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_i_t = torch.autograd.grad(A_i, t, grad_outputs=torch.ones_like(A_i),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_r_x = torch.autograd.grad(A_r, x, grad_outputs=torch.ones_like(A_r),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_i_x = torch.autograd.grad(A_i, x, grad_outputs=torch.ones_like(A_i),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_r_y = torch.autograd.grad(A_r, y, grad_outputs=torch.ones_like(A_r),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_i_y = torch.autograd.grad(A_i, y, grad_outputs=torch.ones_like(A_i),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_r_xx = torch.autograd.grad(A_r_x, x, grad_outputs=torch.ones_like(A_r_x),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_r_yy = torch.autograd.grad(A_r_y, y, grad_outputs=torch.ones_like(A_r_y),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_i_xx = torch.autograd.grad(A_i_x, x, grad_outputs=torch.ones_like(A_i_x),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_i_yy = torch.autograd.grad(A_i_y, y, grad_outputs=torch.ones_like(A_i_y),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        lapA_r = A_r_xx + A_r_yy\n",
    "        lapA_i = A_i_xx + A_i_yy\n",
    "\n",
    "        A_abs2 = A_r**2 + A_i**2\n",
    "\n",
    "        f_r = A_r_t - mu_vals * A_r - self.delta * lapA_r + A_abs2 * A_r\n",
    "        f_i = A_i_t - mu_vals * A_i - self.delta * lapA_i + A_abs2 * A_i\n",
    "        return f_r, f_i\n",
    "\n",
    "    def loss_pde(self, x_eqs, y_eqs, t_eqs):\n",
    "        f_r, f_i = self.pde_residual(x_eqs, y_eqs, t_eqs)\n",
    "        return torch.mean(f_r**2 + f_i**2)\n",
    "\n",
    "    def loss_data(self, x_data, y_data, t_data, A_r_data, A_i_data):\n",
    "        A_r_pred, A_i_pred = self.net_A(x_data, y_data, t_data)\n",
    "        return torch.mean((A_r_pred - A_r_data)**2 + (A_i_pred - A_i_data)**2)\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        x_data, y_data, t_data, A_r_data, A_i_data,\n",
    "        x_eqs, y_eqs, t_eqs,\n",
    "        n_epochs=200000,\n",
    "        lr=1e-3,\n",
    "        model_name=\"MyModel\",\n",
    "        output_dir=\"./results\",\n",
    "        video_freq=10000,\n",
    "        state_exp=None,\n",
    "        myu_full_exp=None,\n",
    "        x_vals=None,\n",
    "        y_vals=None,\n",
    "        t_vals=None,\n",
    "        device=\"cpu\"\n",
    "    ):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        model_folder = os.path.join(output_dir, model_name)\n",
    "        os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            optimizer.zero_grad()\n",
    "            pde_loss = self.loss_pde(x_eqs, y_eqs, t_eqs)\n",
    "            data_loss = self.loss_data(x_data, y_data, t_data, A_r_data, A_i_data)\n",
    "            loss = data_loss + self.weight_pde * pde_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(f\"Epoch {epoch}: Total={loss.item():.4e}, Data={data_loss.item():.4e}, PDE={pde_loss.item():.4e}\")\n",
    "\n",
    "            if epoch % video_freq == 0 and epoch > 0:\n",
    "                vid_path = os.path.join(model_folder, f\"{model_name}_epoch_{epoch}_video.mp4\")\n",
    "                mdl_path = os.path.join(model_folder, f\"{model_name}_epoch_{epoch}_trained.pt\")\n",
    "                generate_video(state_exp, myu_full_exp, self, x_vals, y_vals, t_vals, device, vid_path)\n",
    "                torch.save(self.state_dict(), mdl_path)\n",
    "\n",
    "        final_path = os.path.join(model_folder, f\"{model_name}_final.pt\")\n",
    "        torch.save(self.state_dict(), final_path)\n",
    "        print(f\"Final model saved at {final_path}\")\n",
    "\n",
    "    def expand_myu_full(self, do_binarize=True, scale_255=False):\n",
    "        \"\"\"\n",
    "        Expand mu_small_raw shape = (Nt_down, Nx_down, Ny_down)\n",
    "        to full shape (Nt, Nx, Ny) by:\n",
    "         1) repeat_interleave along time dim by degrade_t\n",
    "         2) repeat_interleave along x,y dims by degrade_x, degrade_y\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            mu_raw = self.mu_small_raw.detach()  # shape (Nt_down, Nx_down, Ny_down)\n",
    "\n",
    "            if do_binarize:\n",
    "                mu_bin = (mu_raw > 0.0).float()\n",
    "            else:\n",
    "                mu_bin = mu_raw\n",
    "\n",
    "            # Expand time dimension\n",
    "            mu_time = mu_bin.repeat_interleave(self.degrade_t, dim=0)\n",
    "            # Shape: (Nt_down * degrade_t, Nx_down, Ny_down) = (Nt, Nx_down, Ny_down)\n",
    "\n",
    "            # Expand spatial dimensions\n",
    "            mu_full_x = mu_time.repeat_interleave(self.degrade_x, dim=1)\n",
    "            mu_full_xy = mu_full_x.repeat_interleave(self.degrade_y, dim=2)\n",
    "            # Shape: (Nt, Nx, Ny)\n",
    "\n",
    "            if scale_255:\n",
    "                mu_full_xy = mu_full_xy * 255.0\n",
    "\n",
    "            return mu_full_xy.cpu().numpy()\n",
    "\n",
    "    def predict(self, x, y, t):\n",
    "        \"\"\"\n",
    "        Evaluate the neural net for A(x, y, t) -> (A_r, A_i) in NumPy form.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            A_r, A_i = self.net_A(x, y, t)  # Forward pass to compute real and imaginary parts\n",
    "        return A_r.cpu().numpy(), A_i.cpu().numpy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "state = np.load(\"../data/test_new/states_processed_cropped.npy\")  # Complex (Nt, Nx, Ny)\n",
    "myu_full = np.load(\"../data/test_new/myus_binarized_processed_cropped.npy\")  # Binary (Nt, Nx, Ny)\n",
    "\n",
    "print(\"State shape:\", state.shape, state.dtype)  # (Nt, Nx, Ny)\n",
    "print(\"Myu shape:  \", myu_full.shape, myu_full.dtype)\n",
    "\n",
    "A_r_data = state.real  # Real part (Nt, Nx, Ny)\n",
    "A_i_data = state.imag  # Imaginary part (Nt, Nx, Ny)\n",
    "\n",
    "Nt, Nx, Ny = state.shape\n",
    "dt, dx, dy = 0.05, 0.3, 0.3  # Temporal and spatial step sizes\n",
    "Nx_down, Ny_down = 10, 10  # Downsampled sizes for `mu`\n",
    "degrade_x, degrade_y = Nx // Nx_down, Ny // Ny_down\n",
    "degrade_t = 50  # Each block of 50 time steps has the same `mu`\n",
    "Nt_down = Nt // degrade_t"
   ],
   "id": "1744bdf2c6d9945",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Randomly sample training points for data and collocation (physics-based loss)\n",
    "n_data = 20000  # Number of data points\n",
    "idx_t = np.random.randint(0, Nt, size=n_data)\n",
    "idx_x = np.random.randint(0, Nx, size=n_data)\n",
    "idx_y = np.random.randint(0, Ny, size=n_data)\n",
    "\n",
    "# Convert sampled indices to physical coordinates\n",
    "t_vals = np.arange(Nt) * dt\n",
    "x_vals = np.arange(Nx) * dx\n",
    "y_vals = np.arange(Ny) * dy\n",
    "\n",
    "t_data_np = t_vals[idx_t]\n",
    "x_data_np = x_vals[idx_x]\n",
    "y_data_np = y_vals[idx_y]\n",
    "\n",
    "# Ground-truth A_r and A_i values\n",
    "Ar_data_np = A_r_data[idx_t, idx_x, idx_y]\n",
    "Ai_data_np = A_i_data[idx_t, idx_x, idx_y]\n",
    "\n",
    "# Convert to tensors\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "x_data_t = torch.tensor(x_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_data_t = torch.tensor(y_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "t_data_t = torch.tensor(t_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "Ar_data_t = torch.tensor(Ar_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "Ai_data_t = torch.tensor(Ai_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# Collocation points for PDE residuals\n",
    "n_coll = 20000\n",
    "t_eqs_np = np.random.uniform(0, t_vals[-1], size=n_coll)\n",
    "x_eqs_np = np.random.uniform(0, x_vals[-1], size=n_coll)\n",
    "y_eqs_np = np.random.uniform(0, y_vals[-1], size=n_coll)\n",
    "\n",
    "x_eqs_t = torch.tensor(x_eqs_np, dtype=torch.float32, requires_grad=True).view(-1, 1).to(device)\n",
    "y_eqs_t = torch.tensor(y_eqs_np, dtype=torch.float32, requires_grad=True).view(-1, 1).to(device)\n",
    "t_eqs_t = torch.tensor(t_eqs_np, dtype=torch.float32, requires_grad=True).view(-1, 1).to(device)"
   ],
   "id": "d1f136e2ecbaa6ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = NPINN_CNN_TIMEBLOCK(\n",
    "    in_channels=3,         # Input channels (time, x, y grid)\n",
    "    out_channels=2,        # Output channels (A_r, A_i)\n",
    "    Nt=Nt, Nx=Nx, Ny=Ny,\n",
    "    Nx_down=Nx_down, Ny_down=Ny_down,\n",
    "    dt=dt, dx=dx, dy=dy,\n",
    "    degrade_x=degrade_x, degrade_y=degrade_y,\n",
    "    degrade_t=degrade_t,\n",
    "    delta=0.01,\n",
    "    weight_pde=0.1,\n",
    "    device=device\n",
    ").to(device)"
   ],
   "id": "876295e8573f6955",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training configuration\n",
    "n_epochs = 200000\n",
    "lr = 1e-3\n",
    "video_freq = 10000  # Save comparison video every 1000 epochs\n",
    "output_dir = \"./results\"\n",
    "model_name = \"CNN_PINN\"\n",
    "\n",
    "# Train the model\n",
    "model.train_model(\n",
    "    x_data_t, y_data_t, t_data_t,\n",
    "    Ar_data_t, Ai_data_t,\n",
    "    x_eqs_t, y_eqs_t, t_eqs_t,\n",
    "    n_epochs=n_epochs,\n",
    "    lr=lr,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    video_freq=video_freq,\n",
    "    state_exp=state,  # Original state for video comparison\n",
    "    myu_full_exp=myu_full,  # Original mu for video comparison\n",
    "    x_vals=x_vals,\n",
    "    y_vals=y_vals,\n",
    "    t_vals=t_vals,\n",
    "    device=device\n",
    ")"
   ],
   "id": "bf101f68faa76009",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T20:50:43.169969Z",
     "start_time": "2025-01-21T20:50:43.141352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class CNNWithDropout(nn.Module):\n",
    "    \"\"\"\n",
    "    A CNN with added dropout layers for regularization.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_layers=6, base_filters=32, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: Number of input channels (e.g., 3 for x, y, t).\n",
    "            out_channels: Number of output channels (e.g., 2 for A_r, A_i).\n",
    "            num_layers: Number of convolutional layers.\n",
    "            base_filters: Number of filters in the first layer.\n",
    "            dropout_rate: Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Conv2d(in_channels, base_filters, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout2d(dropout_rate))\n",
    "\n",
    "        # Intermediate layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(nn.Conv2d(base_filters, base_filters, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout2d(dropout_rate))\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Conv2d(base_filters, out_channels, kernel_size=3, padding=1))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, in_channels, Nx, Ny).\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, out_channels, Nx, Ny).\n",
    "        \"\"\"\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class NPINN_CNN_TIMEBLOCK_WITH_DROPOUT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,         # Input channels (e.g., 3 for (x, y, t))\n",
    "        out_channels,        # Output channels (e.g., 2 for A_r, A_i)\n",
    "        Nt, Nx, Ny,\n",
    "        Nx_down, Ny_down,    # Downsampled domain sizes for mu\n",
    "        dt, dx, dy,\n",
    "        degrade_x, degrade_y,\n",
    "        degrade_t,\n",
    "        delta=0.01,\n",
    "        weight_pde=1.0,\n",
    "        device=\"cpu\",\n",
    "        dropout_rate=0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.delta = delta\n",
    "        self.weight_pde = weight_pde\n",
    "\n",
    "        self.Nt, self.Nx, self.Ny = Nt, Nx, Ny\n",
    "        self.Nx_down, self.Ny_down = Nx_down, Ny_down\n",
    "        self.dt, self.dx, self.dy = dt, dx, dy\n",
    "        self.degrade_x, self.degrade_y = degrade_x, degrade_y\n",
    "        self.degrade_t = degrade_t\n",
    "        self.Nt_down = Nt // degrade_t\n",
    "\n",
    "        # CNN with Dropout for predicting A(x, y, t)\n",
    "        self.cnn = CNNWithDropout(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            num_layers=6,  # Increased number of layers\n",
    "            base_filters=64,  # Increased base filters\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "\n",
    "        # Trainable mu_small (reduced domain in time and space)\n",
    "        init = 0.3 * torch.randn(self.Nt_down, Nx_down, Ny_down)\n",
    "        self.mu_small_raw = nn.Parameter(init.to(device))\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "        return self.net_A(x, y, t)\n",
    "\n",
    "    def net_A(self, x, y, t):\n",
    "        # Concatenate (x, y, t) along channel dimension and reshape for CNN\n",
    "        batch_size = x.shape[0]\n",
    "        inputs = torch.stack([x, y, t], dim=1)  # Shape: [batch_size, 3, 1, 1]\n",
    "        inputs = inputs.view(batch_size, 3, 1, 1)  # Ensure 4D for CNN\n",
    "        outputs = self.cnn(inputs)\n",
    "        A_r, A_i = outputs[:, 0:1, 0, 0], outputs[:, 1:2, 0, 0]\n",
    "        return A_r, A_i\n",
    "\n",
    "    def get_myu_collocation(self, x, y, t):\n",
    "        i = (t[:, 0] / self.dt).round().long().clamp(0, self.Nt - 1)\n",
    "        i_down = (i // self.degrade_t).clamp(0, self.Nt_down - 1)\n",
    "        j_down = (x[:, 0] / (self.dx * self.degrade_x)).floor().long().clamp(0, self.Nx_down - 1)\n",
    "        k_down = (y[:, 0] / (self.dy * self.degrade_y)).floor().long().clamp(0, self.Ny_down - 1)\n",
    "        mu_vals_raw = self.mu_small_raw[i_down, j_down, k_down]\n",
    "        return mu_vals_raw.view(-1, 1)\n",
    "\n",
    "    def pde_residual(self, x, y, t):\n",
    "        A_r, A_i = self.net_A(x, y, t)\n",
    "        mu_vals = self.get_myu_collocation(x, y, t)\n",
    "\n",
    "        A_r_t = torch.autograd.grad(A_r, t, grad_outputs=torch.ones_like(A_r),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_i_t = torch.autograd.grad(A_i, t, grad_outputs=torch.ones_like(A_i),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_r_x = torch.autograd.grad(A_r, x, grad_outputs=torch.ones_like(A_r),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_i_x = torch.autograd.grad(A_i, x, grad_outputs=torch.ones_like(A_i),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_r_y = torch.autograd.grad(A_r, y, grad_outputs=torch.ones_like(A_r),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_i_y = torch.autograd.grad(A_i, y, grad_outputs=torch.ones_like(A_i),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_r_xx = torch.autograd.grad(A_r_x, x, grad_outputs=torch.ones_like(A_r_x),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_r_yy = torch.autograd.grad(A_r_y, y, grad_outputs=torch.ones_like(A_r_y),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        A_i_xx = torch.autograd.grad(A_i_x, x, grad_outputs=torch.ones_like(A_i_x),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "        A_i_yy = torch.autograd.grad(A_i_y, y, grad_outputs=torch.ones_like(A_i_y),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        lapA_r = A_r_xx + A_r_yy\n",
    "        lapA_i = A_i_xx + A_i_yy\n",
    "\n",
    "        A_abs2 = A_r**2 + A_i**2\n",
    "\n",
    "        f_r = A_r_t - mu_vals * A_r - self.delta * lapA_r + A_abs2 * A_r\n",
    "        f_i = A_i_t - mu_vals * A_i - self.delta * lapA_i + A_abs2 * A_i\n",
    "        return f_r, f_i\n",
    "\n",
    "    def loss_pde(self, x_eqs, y_eqs, t_eqs):\n",
    "        f_r, f_i = self.pde_residual(x_eqs, y_eqs, t_eqs)\n",
    "        return torch.mean(f_r**2 + f_i**2)\n",
    "\n",
    "    def loss_data(self, x_data, y_data, t_data, A_r_data, A_i_data):\n",
    "        A_r_pred, A_i_pred = self.net_A(x_data, y_data, t_data)\n",
    "        return torch.mean((A_r_pred - A_r_data)**2 + (A_i_pred - A_i_data)**2)\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        x_data, y_data, t_data, A_r_data, A_i_data,\n",
    "        x_eqs, y_eqs, t_eqs,\n",
    "        n_epochs=200000,\n",
    "        lr=1e-3,\n",
    "        model_name=\"MyModel\",\n",
    "        output_dir=\"./results\",\n",
    "        video_freq=10000,\n",
    "        state_exp=None,\n",
    "        myu_full_exp=None,\n",
    "        x_vals=None,\n",
    "        y_vals=None,\n",
    "        t_vals=None,\n",
    "        device=\"cpu\"\n",
    "    ):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        model_folder = os.path.join(output_dir, model_name)\n",
    "        os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            optimizer.zero_grad()\n",
    "            pde_loss = self.loss_pde(x_eqs, y_eqs, t_eqs)\n",
    "            data_loss = self.loss_data(x_data, y_data, t_data, A_r_data, A_i_data)\n",
    "            loss = data_loss + self.weight_pde * pde_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(f\"Epoch {epoch}: Total={loss.item():.4e}, Data={data_loss.item():.4e}, PDE={pde_loss.item():.4e}\")\n",
    "\n",
    "            if epoch % video_freq == 0 and epoch > 0:\n",
    "                vid_path = os.path.join(model_folder, f\"{model_name}_epoch_{epoch}_video.mp4\")\n",
    "                mdl_path = os.path.join(model_folder, f\"{model_name}_epoch_{epoch}_trained.pt\")\n",
    "                generate_video(state_exp, myu_full_exp, self, x_vals, y_vals, t_vals, device, vid_path)\n",
    "                torch.save(self.state_dict(), mdl_path)\n",
    "\n",
    "        final_path = os.path.join(model_folder, f\"{model_name}_final.pt\")\n",
    "        torch.save(self.state_dict(), final_path)\n",
    "        print(f\"Final model saved at {final_path}\")\n",
    "\n",
    "    def expand_myu_full(self, do_binarize=True, scale_255=False):\n",
    "        \"\"\"\n",
    "        Expand mu_small_raw shape = (Nt_down, Nx_down, Ny_down)\n",
    "        to full shape (Nt, Nx, Ny) by:\n",
    "         1) repeat_interleave along time dim by degrade_t\n",
    "         2) repeat_interleave along x,y dims by degrade_x, degrade_y\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            mu_raw = self.mu_small_raw.detach()  # shape (Nt_down, Nx_down, Ny_down)\n",
    "\n",
    "            if do_binarize:\n",
    "                mu_bin = (mu_raw > 0.0).float()\n",
    "            else:\n",
    "                mu_bin = mu_raw\n",
    "\n",
    "            # Expand time dimension\n",
    "            mu_time = mu_bin.repeat_interleave(self.degrade_t, dim=0)\n",
    "            # Shape: (Nt_down * degrade_t, Nx_down, Ny_down) = (Nt, Nx_down, Ny_down)\n",
    "\n",
    "            # Expand spatial dimensions\n",
    "            mu_full_x = mu_time.repeat_interleave(self.degrade_x, dim=1)\n",
    "            mu_full_xy = mu_full_x.repeat_interleave(self.degrade_y, dim=2)\n",
    "            # Shape: (Nt, Nx, Ny)\n",
    "\n",
    "            if scale_255:\n",
    "                mu_full_xy = mu_full_xy * 255.0\n",
    "\n",
    "            return mu_full_xy.cpu().numpy()\n",
    "\n",
    "    def predict(self, x, y, t):\n",
    "        \"\"\"\n",
    "        Evaluate the neural net for A(x, y, t) -> (A_r, A_i) in NumPy form.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            A_r, A_i = self.net_A(x, y, t)  # Forward pass to compute real and imaginary parts\n",
    "        return A_r.cpu().numpy(), A_i.cpu().numpy()\n"
   ],
   "id": "d054b86dbf9c03f1",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-21T21:09:25.154152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load state and mu data\n",
    "state = np.load(\"../data/test_new/states_processed_cropped.npy\")  # Complex (Nt, Nx, Ny)\n",
    "myu_full = np.load(\"../data/test_new/myus_binarized_processed_cropped.npy\")  # Binary (Nt, Nx, Ny)\n",
    "\n",
    "print(\"State shape:\", state.shape, state.dtype)  # (Nt, Nx, Ny)\n",
    "print(\"Mu shape:   \", myu_full.shape, myu_full.dtype)\n",
    "\n",
    "# Real and imaginary parts of the state\n",
    "A_r_data = state.real  # Real part\n",
    "A_i_data = state.imag  # Imaginary part\n",
    "\n",
    "# Extract domain sizes\n",
    "Nt, Nx, Ny = state.shape\n",
    "dt, dx, dy = 0.05, 0.3, 0.3  # Temporal and spatial step sizes\n",
    "Nx_down, Ny_down = 10, 10  # Downsampled sizes for `mu`\n",
    "degrade_x, degrade_y = Nx // Nx_down, Ny // Ny_down\n",
    "degrade_t = 50  # Each block of 50 time steps has the same `mu`\n",
    "Nt_down = Nt // degrade_t\n",
    "\n",
    "# Prepare training and collocation points\n",
    "n_data = 20000  # Number of data points\n",
    "idx_t = np.random.randint(0, Nt, size=n_data)\n",
    "idx_x = np.random.randint(0, Nx, size=n_data)\n",
    "idx_y = np.random.randint(0, Ny, size=n_data)\n",
    "\n",
    "# Convert indices to physical coordinates\n",
    "t_vals = np.arange(Nt) * dt\n",
    "x_vals = np.arange(Nx) * dx\n",
    "y_vals = np.arange(Ny) * dy\n",
    "\n",
    "t_data_np = t_vals[idx_t]\n",
    "x_data_np = x_vals[idx_x]\n",
    "y_data_np = y_vals[idx_y]\n",
    "\n",
    "# Ground-truth real and imaginary parts\n",
    "Ar_data_np = A_r_data[idx_t, idx_x, idx_y]\n",
    "Ai_data_np = A_i_data[idx_t, idx_x, idx_y]\n",
    "\n",
    "# Convert to tensors\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "x_data_t = torch.tensor(x_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_data_t = torch.tensor(y_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "t_data_t = torch.tensor(t_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "Ar_data_t = torch.tensor(Ar_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "Ai_data_t = torch.tensor(Ai_data_np, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# Collocation points for PDE residuals\n",
    "n_coll = 20000\n",
    "t_eqs_np = np.random.uniform(0, t_vals[-1], size=n_coll)\n",
    "x_eqs_np = np.random.uniform(0, x_vals[-1], size=n_coll)\n",
    "y_eqs_np = np.random.uniform(0, y_vals[-1], size=n_coll)\n",
    "\n",
    "x_eqs_t = torch.tensor(x_eqs_np, dtype=torch.float32, requires_grad=True).view(-1, 1).to(device)\n",
    "y_eqs_t = torch.tensor(y_eqs_np, dtype=torch.float32, requires_grad=True).view(-1, 1).to(device)\n",
    "t_eqs_t = torch.tensor(t_eqs_np, dtype=torch.float32, requires_grad=True).view(-1, 1).to(device)\n",
    "\n",
    "# Initialize the model\n",
    "model = NPINN_CNN_TIMEBLOCK_WITH_DROPOUT(\n",
    "    in_channels=3,         # Input channels (time, x, y grid)\n",
    "    out_channels=2,        # Output channels (A_r, A_i)\n",
    "    Nt=Nt, Nx=Nx, Ny=Ny,\n",
    "    Nx_down=Nx_down, Ny_down=Ny_down,\n",
    "    dt=dt, dx=dx, dy=dy,\n",
    "    degrade_x=degrade_x, degrade_y=degrade_y,\n",
    "    degrade_t=degrade_t,\n",
    "    delta=0.01,\n",
    "    weight_pde=0.1,\n",
    "    dropout_rate=0.5,      # Dropout probability\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Training configuration\n",
    "n_epochs = 200000\n",
    "lr = 1e-3\n",
    "video_freq = 10000  # Save comparison video every 10000 epochs\n",
    "output_dir = \"./results\"\n",
    "model_name = \"CNN_PINN_Dropout\"\n",
    "\n",
    "print(\"Initial mu_small_raw:\")\n",
    "print(model.mu_small_raw)\n",
    "# Train the model\n",
    "model.train_model(\n",
    "    x_data_t, y_data_t, t_data_t,\n",
    "    Ar_data_t, Ai_data_t,\n",
    "    x_eqs_t, y_eqs_t, t_eqs_t,\n",
    "    n_epochs=n_epochs,\n",
    "    lr=lr,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    video_freq=video_freq,\n",
    "    state_exp=state,  # Original state for video comparison\n",
    "    myu_full_exp=myu_full,  # Original mu for video comparison\n",
    "    x_vals=x_vals,\n",
    "    y_vals=y_vals,\n",
    "    t_vals=t_vals,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Updated mu_small_raw:\")\n",
    "print(model.mu_small_raw)\n",
    "# Save the final trained model\n",
    "final_model_path = f\"{output_dir}/{model_name}_final.pt\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"Final model saved at {final_model_path}\")"
   ],
   "id": "25fbbbdee4872f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape: (350, 530, 880) complex128\n",
      "Mu shape:    (350, 530, 880) uint16\n",
      "Initial mu_small_raw:\n",
      "Parameter containing:\n",
      "tensor([[[-0.1337, -0.0711, -0.4917, -0.0978,  0.3985, -0.1620, -0.3516,\n",
      "          -0.1934, -0.0863,  0.2276],\n",
      "         [ 0.1529, -0.3025, -0.4092, -0.1418,  0.2641, -0.3506, -0.2351,\n",
      "          -0.0710,  0.0350, -0.0425],\n",
      "         [-0.1450, -0.1569,  0.1331,  0.2254, -0.0472,  0.2859, -0.1885,\n",
      "          -0.1547,  0.3316, -0.1803],\n",
      "         [ 0.4727, -0.1520, -0.4075,  0.3553,  0.1617,  0.1352, -0.0836,\n",
      "           0.2357, -0.1484, -0.2308],\n",
      "         [ 0.3905, -0.1791,  0.6272,  0.2286,  0.0017,  0.2941,  0.5514,\n",
      "          -0.1074, -0.1156,  0.4443],\n",
      "         [ 0.1383,  0.2162, -0.3742,  0.3170,  0.1288, -0.0113, -0.0124,\n",
      "           0.2511,  0.4652, -0.1399],\n",
      "         [-0.0333,  0.1135,  0.1674,  0.3537,  0.0588, -0.6603,  0.5049,\n",
      "          -0.2520, -0.1286,  0.2642],\n",
      "         [ 0.4199, -0.0227,  0.1994,  0.2506, -0.2709, -0.1783,  0.1414,\n",
      "           0.1434, -0.0756,  0.7943],\n",
      "         [-0.1023,  0.3216, -0.1713, -0.0374, -0.1100,  0.5480,  0.3504,\n",
      "           0.1333,  0.2498, -0.1648],\n",
      "         [ 0.2783,  0.2305,  0.5222, -0.1633, -0.0919, -0.3034, -0.3153,\n",
      "          -0.0102, -0.0759, -0.4267]],\n",
      "\n",
      "        [[-0.3927,  0.4095, -0.0676,  0.4118, -0.0403, -0.3077, -0.0449,\n",
      "           0.0555, -0.0504, -0.6177],\n",
      "         [-0.3085,  0.1319,  0.3874,  0.3770, -0.0013,  0.2098,  0.3382,\n",
      "           0.1341,  0.5282,  0.2109],\n",
      "         [ 0.1069, -0.0598,  0.0489, -0.1353,  0.3524, -0.2308,  0.2269,\n",
      "           0.5077, -0.2787,  0.6550],\n",
      "         [-0.4608, -0.0069, -0.2987, -0.2348, -0.3192, -0.1466,  0.7192,\n",
      "           0.1550, -0.0149, -0.6052],\n",
      "         [-0.3144,  0.1450, -0.1948, -0.3676, -0.2392,  0.3066,  0.4624,\n",
      "           0.1991, -0.0621, -0.3264],\n",
      "         [ 0.0084, -0.2689, -0.1695,  0.7296, -0.1958, -0.0374,  0.5655,\n",
      "           0.0037,  0.0861, -0.4816],\n",
      "         [ 0.1457,  0.2641,  0.3126, -0.1387, -0.1552, -0.3865, -0.2056,\n",
      "           0.0482, -0.2280, -0.4027],\n",
      "         [-0.1946, -0.3905, -0.1690, -0.0069,  0.1605,  0.1500,  0.0631,\n",
      "          -0.0083,  0.0698,  0.7965],\n",
      "         [ 0.0109, -0.3217,  0.2998, -0.6329, -0.1270,  0.1421, -0.2527,\n",
      "           0.1961,  0.1528, -0.1133],\n",
      "         [ 0.1103,  0.2306, -0.1109,  0.0728,  0.3513, -0.0030,  0.2522,\n",
      "           0.0890,  0.2727, -0.3656]],\n",
      "\n",
      "        [[-0.1505,  0.7845,  0.1369, -0.5071,  0.0969,  0.4550, -0.0742,\n",
      "           0.4076, -0.0656,  0.3998],\n",
      "         [-0.0397, -0.5370, -0.0581, -0.6583, -0.0390,  0.2456,  0.1318,\n",
      "          -0.2286,  0.6429,  0.2343],\n",
      "         [-0.4251, -0.0697,  0.1416,  0.3709, -0.3239,  0.0870, -0.4827,\n",
      "          -0.1906, -0.0266, -0.0308],\n",
      "         [ 0.0973, -0.5544, -0.0993,  0.3652,  0.5451,  0.0531, -0.1864,\n",
      "           0.2661, -0.1516, -0.2625],\n",
      "         [-0.0437, -0.3633, -0.2547, -0.2038,  0.4126, -0.1863,  0.3584,\n",
      "          -0.0164, -0.1119,  0.1748],\n",
      "         [-0.2725,  0.1135,  0.3854, -0.2356,  0.2429, -0.2806,  0.3201,\n",
      "          -0.3526,  0.5559,  0.5550],\n",
      "         [-0.1659, -0.3845, -0.2222, -0.0814, -0.2399,  0.3089, -0.1151,\n",
      "          -0.0087,  0.5997,  0.8983],\n",
      "         [ 0.2609, -0.0060, -0.2803,  0.0019, -0.4541, -0.1746, -0.3509,\n",
      "          -0.0708, -0.1098,  0.7370],\n",
      "         [ 0.2517, -0.1534, -0.1628,  0.2022, -0.1462, -0.0606, -0.0080,\n",
      "           0.1563, -0.1283, -0.3343],\n",
      "         [-0.1517,  0.0032,  0.3574, -0.6807, -0.1052, -0.0307,  0.0289,\n",
      "           0.2811, -0.2675, -0.1201]],\n",
      "\n",
      "        [[-0.0387, -0.2668, -0.0548, -0.2734,  0.2158,  0.3933,  0.0532,\n",
      "          -0.2244, -0.1652,  0.4596],\n",
      "         [ 0.4371,  0.2938, -0.3753,  0.1139,  0.1430,  0.3493, -0.0563,\n",
      "           0.1016, -0.4328,  0.3265],\n",
      "         [ 0.0518, -0.0728, -0.5121, -0.0835, -0.3084, -0.0766, -0.0418,\n",
      "          -0.8190, -0.0032,  0.3825],\n",
      "         [-0.2970, -0.3419,  0.2984, -0.4209,  0.4824,  0.1290,  0.6952,\n",
      "           0.3528, -0.2080,  0.5401],\n",
      "         [ 0.2322,  0.0368,  0.4742, -0.0460,  0.6168, -0.4826,  0.4666,\n",
      "           0.4750, -0.0330, -0.1568],\n",
      "         [ 0.1353, -0.1762,  0.1696,  0.1979, -0.0691,  0.1019, -0.0942,\n",
      "          -0.5213, -0.2156,  0.2141],\n",
      "         [-0.2161,  0.0278,  0.0760, -0.4643,  0.0916,  0.0229,  0.3100,\n",
      "           0.1034,  0.1807, -0.0639],\n",
      "         [-0.3178, -0.1059,  0.1116,  0.3056, -0.4544, -0.4328,  0.3065,\n",
      "           0.0641,  0.0708,  0.0181],\n",
      "         [ 0.2885,  0.4555, -0.0781, -0.1429, -0.3051, -0.6097,  0.3798,\n",
      "           0.3472, -0.1739,  0.7384],\n",
      "         [ 0.2844,  0.2886,  0.5500, -0.0048, -0.0247, -0.0156,  0.4874,\n",
      "           0.3221,  0.1307,  0.3260]],\n",
      "\n",
      "        [[ 0.0425, -0.2574, -0.2625,  0.2432,  0.1485, -0.3146, -0.2535,\n",
      "           0.5884, -0.1834, -0.2309],\n",
      "         [-0.1992,  0.0767, -0.2288,  0.4033,  0.0404,  0.0783,  0.4936,\n",
      "          -0.0126,  0.3195, -0.3815],\n",
      "         [ 0.6185,  0.3696,  0.2823, -0.0527, -0.3073,  0.1833,  0.1364,\n",
      "          -0.0592,  0.5671,  0.2634],\n",
      "         [-0.2662,  0.4962, -0.2604, -0.7483,  0.0674,  0.0147, -0.1260,\n",
      "           0.2109, -0.2551, -0.3081],\n",
      "         [-0.0447, -0.2995, -0.1161, -0.0277,  0.0539,  0.1362,  0.2257,\n",
      "          -0.1482,  0.3360, -0.2041],\n",
      "         [ 0.7121,  0.4067, -0.0801,  0.2444, -0.2498, -0.2357,  0.1732,\n",
      "           0.1230, -0.1456, -0.1537],\n",
      "         [ 0.4894, -0.4355, -0.2127,  0.0832,  0.7026,  0.0814,  0.1772,\n",
      "           0.1815,  0.6076,  0.0559],\n",
      "         [-0.0857,  0.1103,  0.4305,  0.0730, -0.1901, -0.0841, -0.0865,\n",
      "          -0.1253,  0.0148, -0.4130],\n",
      "         [-0.2314, -0.1581,  0.0996, -0.2862,  0.3549,  0.2214,  0.1689,\n",
      "           0.0664, -0.6129,  0.1706],\n",
      "         [-0.1252, -0.2255, -0.2193,  0.0787, -0.2995, -0.2231, -0.0474,\n",
      "          -0.5677, -0.2803, -0.4753]],\n",
      "\n",
      "        [[ 0.0176,  0.0388, -0.4015, -0.0907, -0.0426,  0.1350,  0.1526,\n",
      "          -0.4846,  0.1884, -0.2881],\n",
      "         [ 0.1117, -0.0589,  0.2281,  0.2756, -0.0953, -0.4666, -0.1236,\n",
      "           0.0815,  0.3721, -0.0294],\n",
      "         [-0.3228, -0.0117,  0.2869, -0.2305,  0.0335, -0.3401,  0.1080,\n",
      "           0.4430, -0.2205, -0.2802],\n",
      "         [-0.1353, -0.1374, -0.1185, -0.0546,  0.2971, -0.1330, -0.2302,\n",
      "          -0.2210, -0.1194,  0.0457],\n",
      "         [-0.1520,  0.1373,  0.0263, -0.0247, -0.2447, -0.0663,  0.5211,\n",
      "          -0.3261, -0.1607,  0.1674],\n",
      "         [ 0.0468,  0.1595, -0.1483, -0.0673, -0.2179, -0.4527,  0.2462,\n",
      "          -0.0590, -0.0205, -0.2557],\n",
      "         [-0.1145,  0.5059,  0.1197,  0.2837, -0.6083, -0.2827, -0.3247,\n",
      "          -0.4949,  0.1510, -0.0505],\n",
      "         [-0.1945,  0.2663,  0.4542, -0.0010, -0.6876,  0.2680, -0.0975,\n",
      "           0.0733,  0.4351,  0.0174],\n",
      "         [ 0.2896,  0.0281,  0.5295,  0.0214,  0.0322, -0.7698,  0.0392,\n",
      "          -0.1056, -0.0639,  0.0094],\n",
      "         [-0.0262, -0.0497, -0.4122, -0.3039,  0.0995, -0.3137,  0.2658,\n",
      "           0.1328,  0.3784,  0.2036]],\n",
      "\n",
      "        [[-0.2496,  0.1069,  0.1909, -0.2254,  0.1151,  0.2968,  0.2056,\n",
      "           0.2141, -0.3867,  0.1122],\n",
      "         [ 0.2136, -0.2846,  0.2889, -0.2590, -0.3197,  0.3930,  0.1445,\n",
      "          -0.0586, -0.5715, -0.5085],\n",
      "         [ 0.1912, -0.0214,  0.1639, -0.2039, -0.1765,  0.0965, -0.1487,\n",
      "           0.1404,  0.5075,  0.0180],\n",
      "         [ 0.5892, -0.2478, -0.0947, -0.5677, -0.5680, -0.2370, -0.2816,\n",
      "           0.2842,  0.2178,  0.5156],\n",
      "         [-0.6248, -0.2271, -0.1153, -0.0020,  0.2466,  0.2076,  0.6958,\n",
      "          -0.2583, -0.5584, -0.2133],\n",
      "         [-0.2741,  0.0612,  0.4634,  0.1272, -0.2490,  0.3126, -0.2202,\n",
      "          -0.1346,  0.0350,  0.3467],\n",
      "         [ 0.4931,  0.4588,  0.0207,  0.2742, -0.0204, -0.4523, -0.0670,\n",
      "           0.4524, -0.3575, -0.2618],\n",
      "         [ 0.0862,  0.6492, -0.2807,  0.0150, -0.0986,  0.3991,  0.1509,\n",
      "           0.3158, -0.2795, -0.3275],\n",
      "         [ 0.1965,  0.0302, -0.0938,  0.2290,  0.2125,  0.1649,  0.0019,\n",
      "           0.0564,  0.4705,  0.2262],\n",
      "         [ 0.1848, -0.1131,  0.4327, -0.2370,  0.4525, -0.6603, -0.1396,\n",
      "           0.3238, -0.1823, -0.6050]]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/200000 [00:00<10:57:25,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Total=3.7807e-01, Data=3.7806e-01, PDE=4.4449e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 502/200000 [00:51<5:43:52,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: Total=2.2827e-01, Data=2.2803e-01, PDE=2.4031e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1002/200000 [01:43<5:47:35,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000: Total=2.1490e-01, Data=2.1421e-01, PDE=6.8202e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1502/200000 [02:35<5:42:52,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500: Total=2.1059e-01, Data=2.0960e-01, PDE=9.8863e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2002/200000 [03:27<5:44:38,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000: Total=2.0876e-01, Data=2.0781e-01, PDE=9.5204e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2502/200000 [04:19<5:37:23,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2500: Total=2.0897e-01, Data=2.0792e-01, PDE=1.0490e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3002/200000 [05:11<5:40:54,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000: Total=2.0850e-01, Data=2.0744e-01, PDE=1.0611e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3469/200000 [05:59<5:36:50,  9.72it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1da709a7687f6363"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
